{
   "cells":[
      {
         "cell_type":"markdown",
         "metadata":{
            
         },
         "source":[
            "# Prepare the unannotated corpus for doccano"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":1,
         "metadata":{
            
         },
         "outputs":[
            
         ],
         "source":[
            "import os\n",
            "from glob import glob\n",
            "import csv\n",
            "import pandas as pd\n",
            "import re\n",
            "import json"
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            
         },
         "source":[
            "# Load data"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":2,
         "metadata":{
            
         },
         "outputs":[
            
         ],
         "source":[
            "from utils import load_conll"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":3,
         "metadata":{
            
         },
         "outputs":[
            
         ],
         "source":[
            "texts, tags = load_conll('08272022.conll')"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":4,
         "metadata":{
            
         },
         "outputs":[
            
         ],
         "source":[
            "from sklearn.model_selection import train_test_split\n",
            "\n",
            "train_texts, val_texts, train_tags, val_tags = train_test_split(texts, tags, test_size=.2, random_state=7)"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":5,
         "metadata":{
            
         },
         "outputs":[
            {
               "name":"stdout",
               "output_type":"stream",
               "text":[
                  "Fig \t\t O\n",
                  ". \t\t O\n",
                  "11 \t\t O\n",
                  "The \t\t O\n",
                  "plot \t\t O\n",
                  "of \t\t O\n",
                  "ln \t\t B-P\n",
                  "[ \t\t I-P\n",
                  "ɛ \t\t I-P\n",
                  "/ \t\t I-P\n",
                  "σ−1 \t\t I-P\n",
                  "/ \t\t I-P\n",
                  "E \t\t I-P\n",
                  "] \t\t I-P\n",
                  "vs \t\t I-P\n",
                  ". \t\t I-P\n",
                  "ln \t\t I-P\n",
                  "ɛ \t\t L-P\n",
                  "of \t\t O\n",
                  "neat \t\t U-S\n",
                  "and \t\t O\n",
                  "nanophased \t\t B-G\n",
                  "epoxy \t\t L-G\n",
                  ". \t\t O\n"
               ]
            }
         ],
         "source":[
            "for i,j in zip(train_texts[3],train_tags[3]):\n",
            "    print(i,'\\t\\t',j)"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":6,
         "metadata":{
            
         },
         "outputs":[
            
         ],
         "source":[
            "from torch.utils.data import Dataset, DataLoader\n",
            "import torch\n",
            "import numpy as np\n",
            "# modified from https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Custom_Named_Entity_Recognition_with_BERT_only_first_wordpiece.ipynb#scrollTo=jrkdZBLYHVcB\n",
            "class T5Dataset(Dataset):\n",
            "    def __init__(self, tokens, tags, tokenizer, max_len, task_prefix):\n",
            "        self.len = len(tokens)\n",
            "        self.tokens = tokens\n",
            "        self.tags = tags\n",
            "        self.tokenizer = tokenizer\n",
            "        self.max_len = max_len\n",
            "        self.task_prefix = task_prefix\n",
            "        # create encodings for tokens and labels\n",
            "        self.unique_tags = set(tag for doc in tags for tag in doc)\n",
            "        self.tag2id = {tag: _id for _id, tag in enumerate(self.unique_tags)}\n",
            "        self.id2tag = {_id: tag for tag, _id in self.tag2id.items()}\n",
            "\n",
            "    def __getitem__(self, index):\n",
            "        # step 1: get the sentence and word labels (skip, we already have it)\n",
            "\n",
            "        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
            "        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n",
            "        encoding = self.tokenizer(self.task_prefix.split() + self.tokens[index],\n",
            "                                  is_split_into_words=True,\n",
            "#                                   return_offsets_mapping=True,\n",
            "                                  padding='max_length',\n",
            "                                  truncation=True,\n",
            "                                  max_length=self.max_len)\n",
            "        # step 3: use tokenizer to encode labels as a sentence\n",
            "        target_encoding = self.tokenizer(self.tags[index],\n",
            "                                         is_split_into_words=True,\n",
            "                                         padding='max_length',\n",
            "                                         truncation=True,\n",
            "                                         max_length=self.max_len)\n",
            "        encoded_labels = torch.as_tensor(target_encoding.input_ids)\n",
            "        # step 4: turn everything into PyTorch tensors\n",
            "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
            "        # replace padding token id's of the labels by -100 so it's ignored by the loss\n",
            "        encoded_labels[encoded_labels == tokenizer.pad_token_id] = -100\n",
            "        item['labels'] = encoded_labels\n",
            "        return item\n",
            "\n",
            "    def __len__(self):\n",
            "        return self.len"
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            
         },
         "source":[
            "# Define evaluation metrics"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":7,
         "metadata":{
            
         },
         "outputs":[
            
         ],
         "source":[
            "import evaluate\n",
            "\n",
            "metric = evaluate.load(\"seqeval\")"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":8,
         "metadata":{
            
         },
         "outputs":[
            
         ],
         "source":[
            "def compute_metrics(eval_preds):\n",
            "    preds, labels = eval_preds\n",
            "    # In case the model returns more than the prediction logits\n",
            "    if isinstance(preds, tuple):\n",
            "        preds = preds[0]\n",
            "\n",
            "    # somehow preds are also getting padded with -100s...\n",
            "    preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n",
            "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
            "\n",
            "    # Replace -100s in the labels as we can't decode them\n",
            "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
            "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
            "\n",
            "    # Some simple post-processing\n",
            "    decoded_preds = [pred.strip().split() for pred in decoded_preds]\n",
            "    decoded_labels = [label.strip().split() for label in decoded_labels]\n",
            "\n",
            "    # More post-processing to make sure the predicted seq has the same len as labels\n",
            "    for i in range(len(decoded_labels)):\n",
            "        label_len = len(decoded_labels[i])\n",
            "        if len(decoded_preds[i]) > label_len:\n",
            "            decoded_preds[i] = decoded_preds[i][:label_len]\n",
            "        elif len(decoded_preds[i]) < label_len:\n",
            "            decoded_preds[i] += ['O']*(label_len-len(decoded_preds[i]))\n",
            "\n",
            "    all_metrics = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
            "    return {\n",
            "        \"precision\": all_metrics[\"overall_precision\"],\n",
            "        \"recall\": all_metrics[\"overall_recall\"],\n",
            "        \"f1\": all_metrics[\"overall_f1\"],\n",
            "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
            "    }"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":9,
         "metadata":{
            
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  
               ]
            },
            {
               "data":{
                  "text/plain":[
                     "{'P': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
                     " 'overall_precision': 1.0,\n",
                     " 'overall_recall': 1.0,\n",
                     " 'overall_f1': 1.0,\n",
                     " 'overall_accuracy': 0.8571428571428571}"
                  ]
               },
               "execution_count":9,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "predictions = [['O','B-P','L-P'],['N','O','O','O']]\n",
            "references = [['O','B-P','L-P'],['M','O','O','O']]\n",
            "metric.compute(predictions=predictions,references=references)"
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            
         },
         "source":[
            "# T5 pretrained"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":9,
         "metadata":{
            
         },
         "outputs":[
            
         ],
         "source":[
            "from transformers import T5TokenizerFast, T5ForConditionalGeneration"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":10,
         "metadata":{
            
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "/home/nanomineduke/anaconda3/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5_fast.py:166: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
                  "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
                  "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
                  "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
                  "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
                  "  FutureWarning,\n"
               ]
            }
         ],
         "source":[
            "tokenizer = T5TokenizerFast.from_pretrained(\"t5-base\",add_prefix_space=True)"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":11,
         "metadata":{
            
         },
         "outputs":[
            
         ],
         "source":[
            "training_set = T5Dataset(train_texts, train_tags, tokenizer, max_len=200, task_prefix='')\n",
            "val_set = T5Dataset(val_texts, val_tags, tokenizer, max_len=200, task_prefix='')"
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            
         },
         "source":[
            "**Assumption**: Padding fixed to 200."
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            
         },
         "source":[
            "### Base model"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":12,
         "metadata":{
            
         },
         "outputs":[
            
         ],
         "source":[
            "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":13,
         "metadata":{
            "collapsed":true
         },
         "outputs":[
            {
               "data":{
                  "text/plain":[
                     "T5Config {\n",
                     "  \"_name_or_path\": \"t5-base\",\n",
                     "  \"architectures\": [\n",
                     "    \"T5WithLMHeadModel\"\n",
                     "  ],\n",
                     "  \"d_ff\": 3072,\n",
                     "  \"d_kv\": 64,\n",
                     "  \"d_model\": 768,\n",
                     "  \"decoder_start_token_id\": 0,\n",
                     "  \"dense_act_fn\": \"relu\",\n",
                     "  \"dropout_rate\": 0.1,\n",
                     "  \"eos_token_id\": 1,\n",
                     "  \"feed_forward_proj\": \"relu\",\n",
                     "  \"initializer_factor\": 1.0,\n",
                     "  \"is_encoder_decoder\": true,\n",
                     "  \"is_gated_act\": false,\n",
                     "  \"layer_norm_epsilon\": 1e-06,\n",
                     "  \"model_type\": \"t5\",\n",
                     "  \"n_positions\": 512,\n",
                     "  \"num_decoder_layers\": 12,\n",
                     "  \"num_heads\": 12,\n",
                     "  \"num_layers\": 12,\n",
                     "  \"output_past\": true,\n",
                     "  \"pad_token_id\": 0,\n",
                     "  \"relative_attention_max_distance\": 128,\n",
                     "  \"relative_attention_num_buckets\": 32,\n",
                     "  \"task_specific_params\": {\n",
                     "    \"summarization\": {\n",
                     "      \"early_stopping\": true,\n",
                     "      \"length_penalty\": 2.0,\n",
                     "      \"max_length\": 200,\n",
                     "      \"min_length\": 30,\n",
                     "      \"no_repeat_ngram_size\": 3,\n",
                     "      \"num_beams\": 4,\n",
                     "      \"prefix\": \"summarize: \"\n",
                     "    },\n",
                     "    \"translation_en_to_de\": {\n",
                     "      \"early_stopping\": true,\n",
                     "      \"max_length\": 300,\n",
                     "      \"num_beams\": 4,\n",
                     "      \"prefix\": \"translate English to German: \"\n",
                     "    },\n",
                     "    \"translation_en_to_fr\": {\n",
                     "      \"early_stopping\": true,\n",
                     "      \"max_length\": 300,\n",
                     "      \"num_beams\": 4,\n",
                     "      \"prefix\": \"translate English to French: \"\n",
                     "    },\n",
                     "    \"translation_en_to_ro\": {\n",
                     "      \"early_stopping\": true,\n",
                     "      \"max_length\": 300,\n",
                     "      \"num_beams\": 4,\n",
                     "      \"prefix\": \"translate English to Romanian: \"\n",
                     "    }\n",
                     "  },\n",
                     "  \"transformers_version\": \"4.21.3\",\n",
                     "  \"use_cache\": true,\n",
                     "  \"vocab_size\": 32128\n",
                     "}"
                  ]
               },
               "execution_count":13,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "model.config"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":13,
         "metadata":{
            
         },
         "outputs":[
            
         ],
         "source":[
            "from transformers import Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
            "\n",
            "args = Seq2SeqTrainingArguments(\n",
            "    \"T5-pretrained-labelseq-ner\",\n",
            "    evaluation_strategy=\"epoch\",\n",
            "    save_strategy=\"epoch\",\n",
            "    learning_rate=1e-4,\n",
            "    num_train_epochs=10,\n",
            "    weight_decay=0.01,\n",
            "    predict_with_generate=True,\n",
            "    seed=7,\n",
            "#     no_cuda=True,\n",
            ")\n",
            "\n",
            "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":15,
         "metadata":{
            "scrolled":true
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "/home/nanomineduke/anaconda3/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
                  "  FutureWarning,\n",
                  "***** Running training *****\n",
                  "  Num examples = 3045\n",
                  "  Num Epochs = 10\n",
                  "  Instantaneous batch size per device = 8\n",
                  "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
                  "  Gradient Accumulation steps = 1\n",
                  "  Total optimization steps = 3810\n"
               ]
            },
            {
               "data":{
                  "text/html":[
                     "\n",
                     "    <div>\n",
                     "      \n",
                     "      <progress value='3810' max='3810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                     "      [3810/3810 52:32, Epoch 10/10]\n",
                     "    </div>\n",
                     "    <table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     " <tr style=\"text-align: left;\">\n",
                     "      <th>Epoch</th>\n",
                     "      <th>Training Loss</th>\n",
                     "      <th>Validation Loss</th>\n",
                     "      <th>Precision</th>\n",
                     "      <th>Recall</th>\n",
                     "      <th>F1</th>\n",
                     "      <th>Accuracy</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <td>1</td>\n",
                     "      <td>No log</td>\n",
                     "      <td>0.307435</td>\n",
                     "      <td>0.251572</td>\n",
                     "      <td>0.090293</td>\n",
                     "      <td>0.132890</td>\n",
                     "      <td>0.698398</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>2</td>\n",
                     "      <td>0.413400</td>\n",
                     "      <td>0.251194</td>\n",
                     "      <td>0.231481</td>\n",
                     "      <td>0.112867</td>\n",
                     "      <td>0.151745</td>\n",
                     "      <td>0.711030</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>3</td>\n",
                     "      <td>0.260700</td>\n",
                     "      <td>0.178076</td>\n",
                     "      <td>0.343583</td>\n",
                     "      <td>0.193378</td>\n",
                     "      <td>0.247472</td>\n",
                     "      <td>0.734992</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>4</td>\n",
                     "      <td>0.187500</td>\n",
                     "      <td>0.160181</td>\n",
                     "      <td>0.374667</td>\n",
                     "      <td>0.211437</td>\n",
                     "      <td>0.270322</td>\n",
                     "      <td>0.744042</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>5</td>\n",
                     "      <td>0.187500</td>\n",
                     "      <td>0.146192</td>\n",
                     "      <td>0.412195</td>\n",
                     "      <td>0.254327</td>\n",
                     "      <td>0.314565</td>\n",
                     "      <td>0.754851</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>6</td>\n",
                     "      <td>0.150800</td>\n",
                     "      <td>0.140893</td>\n",
                     "      <td>0.424242</td>\n",
                     "      <td>0.263356</td>\n",
                     "      <td>0.324977</td>\n",
                     "      <td>0.755242</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>7</td>\n",
                     "      <td>0.125500</td>\n",
                     "      <td>0.138360</td>\n",
                     "      <td>0.444308</td>\n",
                     "      <td>0.273138</td>\n",
                     "      <td>0.338304</td>\n",
                     "      <td>0.756544</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>8</td>\n",
                     "      <td>0.107900</td>\n",
                     "      <td>0.127260</td>\n",
                     "      <td>0.486650</td>\n",
                     "      <td>0.301731</td>\n",
                     "      <td>0.372503</td>\n",
                     "      <td>0.766897</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>9</td>\n",
                     "      <td>0.107900</td>\n",
                     "      <td>0.124863</td>\n",
                     "      <td>0.471564</td>\n",
                     "      <td>0.299473</td>\n",
                     "      <td>0.366314</td>\n",
                     "      <td>0.762925</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>10</td>\n",
                     "      <td>0.092800</td>\n",
                     "      <td>0.124522</td>\n",
                     "      <td>0.487395</td>\n",
                     "      <td>0.305493</td>\n",
                     "      <td>0.375578</td>\n",
                     "      <td>0.766311</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table><p>"
                  ],
                  "text/plain":[
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata":{
                  
               },
               "output_type":"display_data"
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "\n",
                  "\n",
                  "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
                  "\n",
                  "\n"
               ]
            },
            {
               "data":{
                  "text/plain":[
                     "TrainOutput(global_step=3810, training_loss=0.18261083818170343, metrics={'train_runtime': 3153.7099, 'train_samples_per_second': 9.655, 'train_steps_per_second': 1.208, 'total_flos': 7243268659200000.0, 'train_loss': 0.18261083818170343, 'epoch': 10.0})"
                  ]
               },
               "execution_count":15,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "from transformers import Seq2SeqTrainer\n",
            "\n",
            "trainer = Seq2SeqTrainer(\n",
            "    model=model,\n",
            "    args=args,\n",
            "    train_dataset=training_set,\n",
            "    eval_dataset=val_set,\n",
            "    data_collator=data_collator,\n",
            "    compute_metrics=compute_metrics,\n",
            "    tokenizer=tokenizer,\n",
            ")\n",
            "trainer.train()"
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            
         },
         "source":[
            "### num_beams = 5"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":12,
         "metadata":{
            
         },
         "outputs":[
            
         ],
         "source":[
            "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":13,
         "metadata":{
            "collapsed":true
         },
         "outputs":[
            {
               "data":{
                  "text/plain":[
                     "T5Config {\n",
                     "  \"_name_or_path\": \"t5-base\",\n",
                     "  \"architectures\": [\n",
                     "    \"T5WithLMHeadModel\"\n",
                     "  ],\n",
                     "  \"d_ff\": 3072,\n",
                     "  \"d_kv\": 64,\n",
                     "  \"d_model\": 768,\n",
                     "  \"decoder_start_token_id\": 0,\n",
                     "  \"dense_act_fn\": \"relu\",\n",
                     "  \"dropout_rate\": 0.1,\n",
                     "  \"eos_token_id\": 1,\n",
                     "  \"feed_forward_proj\": \"relu\",\n",
                     "  \"initializer_factor\": 1.0,\n",
                     "  \"is_encoder_decoder\": true,\n",
                     "  \"is_gated_act\": false,\n",
                     "  \"layer_norm_epsilon\": 1e-06,\n",
                     "  \"model_type\": \"t5\",\n",
                     "  \"n_positions\": 512,\n",
                     "  \"num_decoder_layers\": 12,\n",
                     "  \"num_heads\": 12,\n",
                     "  \"num_layers\": 12,\n",
                     "  \"output_past\": true,\n",
                     "  \"pad_token_id\": 0,\n",
                     "  \"relative_attention_max_distance\": 128,\n",
                     "  \"relative_attention_num_buckets\": 32,\n",
                     "  \"task_specific_params\": {\n",
                     "    \"summarization\": {\n",
                     "      \"early_stopping\": true,\n",
                     "      \"length_penalty\": 2.0,\n",
                     "      \"max_length\": 200,\n",
                     "      \"min_length\": 30,\n",
                     "      \"no_repeat_ngram_size\": 3,\n",
                     "      \"num_beams\": 4,\n",
                     "      \"prefix\": \"summarize: \"\n",
                     "    },\n",
                     "    \"translation_en_to_de\": {\n",
                     "      \"early_stopping\": true,\n",
                     "      \"max_length\": 300,\n",
                     "      \"num_beams\": 4,\n",
                     "      \"prefix\": \"translate English to German: \"\n",
                     "    },\n",
                     "    \"translation_en_to_fr\": {\n",
                     "      \"early_stopping\": true,\n",
                     "      \"max_length\": 300,\n",
                     "      \"num_beams\": 4,\n",
                     "      \"prefix\": \"translate English to French: \"\n",
                     "    },\n",
                     "    \"translation_en_to_ro\": {\n",
                     "      \"early_stopping\": true,\n",
                     "      \"max_length\": 300,\n",
                     "      \"num_beams\": 4,\n",
                     "      \"prefix\": \"translate English to Romanian: \"\n",
                     "    }\n",
                     "  },\n",
                     "  \"transformers_version\": \"4.21.3\",\n",
                     "  \"use_cache\": true,\n",
                     "  \"vocab_size\": 32128\n",
                     "}"
                  ]
               },
               "execution_count":13,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "model.config"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":15,
         "metadata":{
            
         },
         "outputs":[
            {
               "data":{
                  "text/plain":[
                     "5"
                  ]
               },
               "execution_count":15,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "model.config.update({'num_beams':5})\n",
            "model.config.num_beams"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":16,
         "metadata":{
            
         },
         "outputs":[
            
         ],
         "source":[
            "from transformers import Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
            "\n",
            "args = Seq2SeqTrainingArguments(\n",
            "    \"T5-pretrained-labelseq-ner-nbeams5\",\n",
            "    evaluation_strategy=\"epoch\",\n",
            "    save_strategy=\"epoch\",\n",
            "    learning_rate=1e-4,\n",
            "    num_train_epochs=10,\n",
            "    weight_decay=0.01,\n",
            "    predict_with_generate=True,\n",
            "    generation_num_beams=5,\n",
            "    seed=7,\n",
            "#     no_cuda=True,\n",
            ")\n",
            "\n",
            "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":17,
         "metadata":{
            "scrolled":true
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "/home/nanomineduke/anaconda3/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
                  "  FutureWarning,\n",
                  "***** Running training *****\n",
                  "  Num examples = 3045\n",
                  "  Num Epochs = 10\n",
                  "  Instantaneous batch size per device = 8\n",
                  "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
                  "  Gradient Accumulation steps = 1\n",
                  "  Total optimization steps = 3810\n"
               ]
            },
            {
               "data":{
                  "text/html":[
                     "\n",
                     "    <div>\n",
                     "      \n",
                     "      <progress value='3810' max='3810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                     "      [3810/3810 57:43, Epoch 10/10]\n",
                     "    </div>\n",
                     "    <table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     " <tr style=\"text-align: left;\">\n",
                     "      <th>Epoch</th>\n",
                     "      <th>Training Loss</th>\n",
                     "      <th>Validation Loss</th>\n",
                     "      <th>Precision</th>\n",
                     "      <th>Recall</th>\n",
                     "      <th>F1</th>\n",
                     "      <th>Accuracy</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <td>1</td>\n",
                     "      <td>No log</td>\n",
                     "      <td>0.307435</td>\n",
                     "      <td>0.189459</td>\n",
                     "      <td>0.100075</td>\n",
                     "      <td>0.130970</td>\n",
                     "      <td>0.677432</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>2</td>\n",
                     "      <td>0.413400</td>\n",
                     "      <td>0.251194</td>\n",
                     "      <td>0.223022</td>\n",
                     "      <td>0.116629</td>\n",
                     "      <td>0.153162</td>\n",
                     "      <td>0.706472</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>3</td>\n",
                     "      <td>0.260700</td>\n",
                     "      <td>0.178076</td>\n",
                     "      <td>0.337563</td>\n",
                     "      <td>0.200150</td>\n",
                     "      <td>0.251299</td>\n",
                     "      <td>0.736098</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>4</td>\n",
                     "      <td>0.187500</td>\n",
                     "      <td>0.160181</td>\n",
                     "      <td>0.366751</td>\n",
                     "      <td>0.217457</td>\n",
                     "      <td>0.273028</td>\n",
                     "      <td>0.743652</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>5</td>\n",
                     "      <td>0.187500</td>\n",
                     "      <td>0.146192</td>\n",
                     "      <td>0.406286</td>\n",
                     "      <td>0.262603</td>\n",
                     "      <td>0.319013</td>\n",
                     "      <td>0.753028</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>6</td>\n",
                     "      <td>0.150800</td>\n",
                     "      <td>0.140893</td>\n",
                     "      <td>0.416084</td>\n",
                     "      <td>0.268623</td>\n",
                     "      <td>0.326475</td>\n",
                     "      <td>0.753353</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>7</td>\n",
                     "      <td>0.125500</td>\n",
                     "      <td>0.138360</td>\n",
                     "      <td>0.441141</td>\n",
                     "      <td>0.279157</td>\n",
                     "      <td>0.341935</td>\n",
                     "      <td>0.756739</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>8</td>\n",
                     "      <td>0.107900</td>\n",
                     "      <td>0.127260</td>\n",
                     "      <td>0.483452</td>\n",
                     "      <td>0.307750</td>\n",
                     "      <td>0.376092</td>\n",
                     "      <td>0.765269</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>9</td>\n",
                     "      <td>0.107900</td>\n",
                     "      <td>0.124863</td>\n",
                     "      <td>0.474118</td>\n",
                     "      <td>0.303236</td>\n",
                     "      <td>0.369894</td>\n",
                     "      <td>0.763967</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>10</td>\n",
                     "      <td>0.092800</td>\n",
                     "      <td>0.124522</td>\n",
                     "      <td>0.490476</td>\n",
                     "      <td>0.310008</td>\n",
                     "      <td>0.379899</td>\n",
                     "      <td>0.766180</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table><p>"
                  ],
                  "text/plain":[
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata":{
                  
               },
               "output_type":"display_data"
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "\n",
                  "\n",
                  "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
                  "\n",
                  "\n"
               ]
            },
            {
               "data":{
                  "text/plain":[
                     "TrainOutput(global_step=3810, training_loss=0.18261083818170343, metrics={'train_runtime': 3464.6921, 'train_samples_per_second': 8.789, 'train_steps_per_second': 1.1, 'total_flos': 7243268659200000.0, 'train_loss': 0.18261083818170343, 'epoch': 10.0})"
                  ]
               },
               "execution_count":17,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "from transformers import Seq2SeqTrainer\n",
            "\n",
            "trainer = Seq2SeqTrainer(\n",
            "    model=model,\n",
            "    args=args,\n",
            "    train_dataset=training_set,\n",
            "    eval_dataset=val_set,\n",
            "    data_collator=data_collator,\n",
            "    compute_metrics=compute_metrics,\n",
            "    tokenizer=tokenizer,\n",
            ")\n",
            "trainer.train()"
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            
         },
         "source":[
            "### num_beams = 10"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":18,
         "metadata":{
            "collapsed":true
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "loading configuration file https://huggingface.co/t5-base/resolve/main/config.json from cache at /home/nanomineduke/.cache/huggingface/transformers/91e9fe874e06c44883b535d6c950b8b89d6eaa3298d8e7fb3b2c78039e9f8b7b.66b9637a52aa11e9285cdd6e668cc0df14b3bcf0b6674cf3ba5353c542649637\n",
                  "Model config T5Config {\n",
                  "  \"architectures\": [\n",
                  "    \"T5WithLMHeadModel\"\n",
                  "  ],\n",
                  "  \"d_ff\": 3072,\n",
                  "  \"d_kv\": 64,\n",
                  "  \"d_model\": 768,\n",
                  "  \"decoder_start_token_id\": 0,\n",
                  "  \"dense_act_fn\": \"relu\",\n",
                  "  \"dropout_rate\": 0.1,\n",
                  "  \"eos_token_id\": 1,\n",
                  "  \"feed_forward_proj\": \"relu\",\n",
                  "  \"initializer_factor\": 1.0,\n",
                  "  \"is_encoder_decoder\": true,\n",
                  "  \"is_gated_act\": false,\n",
                  "  \"layer_norm_epsilon\": 1e-06,\n",
                  "  \"model_type\": \"t5\",\n",
                  "  \"n_positions\": 512,\n",
                  "  \"num_decoder_layers\": 12,\n",
                  "  \"num_heads\": 12,\n",
                  "  \"num_layers\": 12,\n",
                  "  \"output_past\": true,\n",
                  "  \"pad_token_id\": 0,\n",
                  "  \"relative_attention_max_distance\": 128,\n",
                  "  \"relative_attention_num_buckets\": 32,\n",
                  "  \"task_specific_params\": {\n",
                  "    \"summarization\": {\n",
                  "      \"early_stopping\": true,\n",
                  "      \"length_penalty\": 2.0,\n",
                  "      \"max_length\": 200,\n",
                  "      \"min_length\": 30,\n",
                  "      \"no_repeat_ngram_size\": 3,\n",
                  "      \"num_beams\": 4,\n",
                  "      \"prefix\": \"summarize: \"\n",
                  "    },\n",
                  "    \"translation_en_to_de\": {\n",
                  "      \"early_stopping\": true,\n",
                  "      \"max_length\": 300,\n",
                  "      \"num_beams\": 4,\n",
                  "      \"prefix\": \"translate English to German: \"\n",
                  "    },\n",
                  "    \"translation_en_to_fr\": {\n",
                  "      \"early_stopping\": true,\n",
                  "      \"max_length\": 300,\n",
                  "      \"num_beams\": 4,\n",
                  "      \"prefix\": \"translate English to French: \"\n",
                  "    },\n",
                  "    \"translation_en_to_ro\": {\n",
                  "      \"early_stopping\": true,\n",
                  "      \"max_length\": 300,\n",
                  "      \"num_beams\": 4,\n",
                  "      \"prefix\": \"translate English to Romanian: \"\n",
                  "    }\n",
                  "  },\n",
                  "  \"transformers_version\": \"4.21.3\",\n",
                  "  \"use_cache\": true,\n",
                  "  \"vocab_size\": 32128\n",
                  "}\n",
                  "\n",
                  "loading weights file https://huggingface.co/t5-base/resolve/main/pytorch_model.bin from cache at /home/nanomineduke/.cache/huggingface/transformers/ab4e948915b067f5cb6e5105f6f85044fd717b133f43240db67899a8fc7b29a2.26934c75adf19ceac3c268b721ba353356b7609c45f5627550326f275a2163b4\n",
                  "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
                  "\n",
                  "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
                  "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
               ]
            }
         ],
         "source":[
            "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":19,
         "metadata":{
            "collapsed":true
         },
         "outputs":[
            {
               "data":{
                  "text/plain":[
                     "T5Config {\n",
                     "  \"_name_or_path\": \"t5-base\",\n",
                     "  \"architectures\": [\n",
                     "    \"T5WithLMHeadModel\"\n",
                     "  ],\n",
                     "  \"d_ff\": 3072,\n",
                     "  \"d_kv\": 64,\n",
                     "  \"d_model\": 768,\n",
                     "  \"decoder_start_token_id\": 0,\n",
                     "  \"dense_act_fn\": \"relu\",\n",
                     "  \"dropout_rate\": 0.1,\n",
                     "  \"eos_token_id\": 1,\n",
                     "  \"feed_forward_proj\": \"relu\",\n",
                     "  \"initializer_factor\": 1.0,\n",
                     "  \"is_encoder_decoder\": true,\n",
                     "  \"is_gated_act\": false,\n",
                     "  \"layer_norm_epsilon\": 1e-06,\n",
                     "  \"model_type\": \"t5\",\n",
                     "  \"n_positions\": 512,\n",
                     "  \"num_decoder_layers\": 12,\n",
                     "  \"num_heads\": 12,\n",
                     "  \"num_layers\": 12,\n",
                     "  \"output_past\": true,\n",
                     "  \"pad_token_id\": 0,\n",
                     "  \"relative_attention_max_distance\": 128,\n",
                     "  \"relative_attention_num_buckets\": 32,\n",
                     "  \"task_specific_params\": {\n",
                     "    \"summarization\": {\n",
                     "      \"early_stopping\": true,\n",
                     "      \"length_penalty\": 2.0,\n",
                     "      \"max_length\": 200,\n",
                     "      \"min_length\": 30,\n",
                     "      \"no_repeat_ngram_size\": 3,\n",
                     "      \"num_beams\": 4,\n",
                     "      \"prefix\": \"summarize: \"\n",
                     "    },\n",
                     "    \"translation_en_to_de\": {\n",
                     "      \"early_stopping\": true,\n",
                     "      \"max_length\": 300,\n",
                     "      \"num_beams\": 4,\n",
                     "      \"prefix\": \"translate English to German: \"\n",
                     "    },\n",
                     "    \"translation_en_to_fr\": {\n",
                     "      \"early_stopping\": true,\n",
                     "      \"max_length\": 300,\n",
                     "      \"num_beams\": 4,\n",
                     "      \"prefix\": \"translate English to French: \"\n",
                     "    },\n",
                     "    \"translation_en_to_ro\": {\n",
                     "      \"early_stopping\": true,\n",
                     "      \"max_length\": 300,\n",
                     "      \"num_beams\": 4,\n",
                     "      \"prefix\": \"translate English to Romanian: \"\n",
                     "    }\n",
                     "  },\n",
                     "  \"transformers_version\": \"4.21.3\",\n",
                     "  \"use_cache\": true,\n",
                     "  \"vocab_size\": 32128\n",
                     "}"
                  ]
               },
               "execution_count":19,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "model.config"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":20,
         "metadata":{
            
         },
         "outputs":[
            {
               "data":{
                  "text/plain":[
                     "10"
                  ]
               },
               "execution_count":20,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "model.config.update({'num_beams':10})\n",
            "model.config.num_beams"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":22,
         "metadata":{
            "collapsed":true
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "PyTorch: setting up devices\n",
                  "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
               ]
            }
         ],
         "source":[
            "from transformers import Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
            "\n",
            "args = Seq2SeqTrainingArguments(\n",
            "    \"T5-pretrained-labelseq-ner-nbeams10\",\n",
            "    evaluation_strategy=\"epoch\",\n",
            "    save_strategy=\"epoch\",\n",
            "    learning_rate=1e-4,\n",
            "    num_train_epochs=10,\n",
            "    weight_decay=0.01,\n",
            "    predict_with_generate=True,\n",
            "    generation_num_beams=10,\n",
            "    seed=7,\n",
            "#     no_cuda=True,\n",
            ")\n",
            "\n",
            "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":23,
         "metadata":{
            "scrolled":true
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "/home/nanomineduke/anaconda3/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
                  "  FutureWarning,\n",
                  "***** Running training *****\n",
                  "  Num examples = 3045\n",
                  "  Num Epochs = 10\n",
                  "  Instantaneous batch size per device = 8\n",
                  "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
                  "  Gradient Accumulation steps = 1\n",
                  "  Total optimization steps = 3810\n"
               ]
            },
            {
               "data":{
                  "text/html":[
                     "\n",
                     "    <div>\n",
                     "      \n",
                     "      <progress value='3810' max='3810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                     "      [3810/3810 1:03:33, Epoch 10/10]\n",
                     "    </div>\n",
                     "    <table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     " <tr style=\"text-align: left;\">\n",
                     "      <th>Epoch</th>\n",
                     "      <th>Training Loss</th>\n",
                     "      <th>Validation Loss</th>\n",
                     "      <th>Precision</th>\n",
                     "      <th>Recall</th>\n",
                     "      <th>F1</th>\n",
                     "      <th>Accuracy</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <td>1</td>\n",
                     "      <td>No log</td>\n",
                     "      <td>0.307435</td>\n",
                     "      <td>0.190743</td>\n",
                     "      <td>0.102333</td>\n",
                     "      <td>0.133203</td>\n",
                     "      <td>0.675544</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>2</td>\n",
                     "      <td>0.413400</td>\n",
                     "      <td>0.251194</td>\n",
                     "      <td>0.223665</td>\n",
                     "      <td>0.116629</td>\n",
                     "      <td>0.153314</td>\n",
                     "      <td>0.706342</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>3</td>\n",
                     "      <td>0.260700</td>\n",
                     "      <td>0.178076</td>\n",
                     "      <td>0.336294</td>\n",
                     "      <td>0.199398</td>\n",
                     "      <td>0.250354</td>\n",
                     "      <td>0.735838</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>4</td>\n",
                     "      <td>0.187500</td>\n",
                     "      <td>0.160181</td>\n",
                     "      <td>0.366751</td>\n",
                     "      <td>0.217457</td>\n",
                     "      <td>0.273028</td>\n",
                     "      <td>0.743717</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>5</td>\n",
                     "      <td>0.187500</td>\n",
                     "      <td>0.146192</td>\n",
                     "      <td>0.406760</td>\n",
                     "      <td>0.262603</td>\n",
                     "      <td>0.319159</td>\n",
                     "      <td>0.752832</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>6</td>\n",
                     "      <td>0.150800</td>\n",
                     "      <td>0.140893</td>\n",
                     "      <td>0.416084</td>\n",
                     "      <td>0.268623</td>\n",
                     "      <td>0.326475</td>\n",
                     "      <td>0.753353</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>7</td>\n",
                     "      <td>0.125500</td>\n",
                     "      <td>0.138360</td>\n",
                     "      <td>0.441141</td>\n",
                     "      <td>0.279157</td>\n",
                     "      <td>0.341935</td>\n",
                     "      <td>0.756739</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>8</td>\n",
                     "      <td>0.107900</td>\n",
                     "      <td>0.127260</td>\n",
                     "      <td>0.483452</td>\n",
                     "      <td>0.307750</td>\n",
                     "      <td>0.376092</td>\n",
                     "      <td>0.765269</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>9</td>\n",
                     "      <td>0.107900</td>\n",
                     "      <td>0.124863</td>\n",
                     "      <td>0.474118</td>\n",
                     "      <td>0.303236</td>\n",
                     "      <td>0.369894</td>\n",
                     "      <td>0.763967</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>10</td>\n",
                     "      <td>0.092800</td>\n",
                     "      <td>0.124522</td>\n",
                     "      <td>0.490476</td>\n",
                     "      <td>0.310008</td>\n",
                     "      <td>0.379899</td>\n",
                     "      <td>0.766180</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table><p>"
                  ],
                  "text/plain":[
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata":{
                  
               },
               "output_type":"display_data"
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "\n",
                  "\n",
                  "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
                  "\n",
                  "\n"
               ]
            },
            {
               "data":{
                  "text/plain":[
                     "TrainOutput(global_step=3810, training_loss=0.18261083818170343, metrics={'train_runtime': 3814.6936, 'train_samples_per_second': 7.982, 'train_steps_per_second': 0.999, 'total_flos': 7243268659200000.0, 'train_loss': 0.18261083818170343, 'epoch': 10.0})"
                  ]
               },
               "execution_count":23,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "from transformers import Seq2SeqTrainer\n",
            "\n",
            "trainer = Seq2SeqTrainer(\n",
            "    model=model,\n",
            "    args=args,\n",
            "    train_dataset=training_set,\n",
            "    eval_dataset=val_set,\n",
            "    data_collator=data_collator,\n",
            "    compute_metrics=compute_metrics,\n",
            "    tokenizer=tokenizer,\n",
            ")\n",
            "trainer.train()"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":24,
         "metadata":{
            "scrolled":true
         },
         "outputs":[
            {
               "data":{
                  "text/plain":[
                     "{'max_length': None, 'num_beams': 10}"
                  ]
               },
               "execution_count":24,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "trainer._gen_kwargs"
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            
         },
         "source":[
            "### num_beams = 5 with force_words_ids"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":13,
         "metadata":{
            
         },
         "outputs":[
            
         ],
         "source":[
            "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":14,
         "metadata":{
            
         },
         "outputs":[
            {
               "data":{
                  "text/plain":[
                     "5"
                  ]
               },
               "execution_count":14,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "model.config.update({'num_beams':5})\n",
            "model.config.num_beams"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":15,
         "metadata":{
            "collapsed":true
         },
         "outputs":[
            {
               "data":{
                  "text/plain":[
                     "T5Config {\n",
                     "  \"_name_or_path\": \"t5-base\",\n",
                     "  \"architectures\": [\n",
                     "    \"T5WithLMHeadModel\"\n",
                     "  ],\n",
                     "  \"d_ff\": 3072,\n",
                     "  \"d_kv\": 64,\n",
                     "  \"d_model\": 768,\n",
                     "  \"decoder_start_token_id\": 0,\n",
                     "  \"dense_act_fn\": \"relu\",\n",
                     "  \"dropout_rate\": 0.1,\n",
                     "  \"eos_token_id\": 1,\n",
                     "  \"feed_forward_proj\": \"relu\",\n",
                     "  \"initializer_factor\": 1.0,\n",
                     "  \"is_encoder_decoder\": true,\n",
                     "  \"is_gated_act\": false,\n",
                     "  \"layer_norm_epsilon\": 1e-06,\n",
                     "  \"model_type\": \"t5\",\n",
                     "  \"n_positions\": 512,\n",
                     "  \"num_beams\": 5,\n",
                     "  \"num_decoder_layers\": 12,\n",
                     "  \"num_heads\": 12,\n",
                     "  \"num_layers\": 12,\n",
                     "  \"output_past\": true,\n",
                     "  \"pad_token_id\": 0,\n",
                     "  \"relative_attention_max_distance\": 128,\n",
                     "  \"relative_attention_num_buckets\": 32,\n",
                     "  \"task_specific_params\": {\n",
                     "    \"summarization\": {\n",
                     "      \"early_stopping\": true,\n",
                     "      \"length_penalty\": 2.0,\n",
                     "      \"max_length\": 200,\n",
                     "      \"min_length\": 30,\n",
                     "      \"no_repeat_ngram_size\": 3,\n",
                     "      \"num_beams\": 4,\n",
                     "      \"prefix\": \"summarize: \"\n",
                     "    },\n",
                     "    \"translation_en_to_de\": {\n",
                     "      \"early_stopping\": true,\n",
                     "      \"max_length\": 300,\n",
                     "      \"num_beams\": 4,\n",
                     "      \"prefix\": \"translate English to German: \"\n",
                     "    },\n",
                     "    \"translation_en_to_fr\": {\n",
                     "      \"early_stopping\": true,\n",
                     "      \"max_length\": 300,\n",
                     "      \"num_beams\": 4,\n",
                     "      \"prefix\": \"translate English to French: \"\n",
                     "    },\n",
                     "    \"translation_en_to_ro\": {\n",
                     "      \"early_stopping\": true,\n",
                     "      \"max_length\": 300,\n",
                     "      \"num_beams\": 4,\n",
                     "      \"prefix\": \"translate English to Romanian: \"\n",
                     "    }\n",
                     "  },\n",
                     "  \"transformers_version\": \"4.21.3\",\n",
                     "  \"use_cache\": true,\n",
                     "  \"vocab_size\": 32128\n",
                     "}"
                  ]
               },
               "execution_count":15,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "model.config"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":16,
         "metadata":{
            
         },
         "outputs":[
            
         ],
         "source":[
            "from transformers import Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
            "\n",
            "args = Seq2SeqTrainingArguments(\n",
            "    \"T5-pretrained-labelseq-ner-nbeams5-force\",\n",
            "    evaluation_strategy=\"epoch\",\n",
            "    save_strategy=\"epoch\",\n",
            "    learning_rate=1e-4,\n",
            "    num_train_epochs=10,\n",
            "    weight_decay=0.01,\n",
            "    predict_with_generate=True,\n",
            "    generation_num_beams=5,\n",
            "    seed=7,\n",
            "#     no_cuda=True,\n",
            ")\n",
            "\n",
            "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":17,
         "metadata":{
            
         },
         "outputs":[
            
         ],
         "source":[
            "force_words_ids = tokenizer(list(training_set.tag2id.keys()), add_special_tokens=False).input_ids"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":18,
         "metadata":{
            "collapsed":true
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "/home/nanomineduke/anaconda3/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
                  "  FutureWarning,\n",
                  "***** Running training *****\n",
                  "  Num examples = 3045\n",
                  "  Num Epochs = 10\n",
                  "  Instantaneous batch size per device = 8\n",
                  "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
                  "  Gradient Accumulation steps = 1\n",
                  "  Total optimization steps = 3810\n"
               ]
            },
            {
               "data":{
                  "text/html":[
                     "\n",
                     "    <div>\n",
                     "      \n",
                     "      <progress value='3810' max='3810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                     "      [3810/3810 1:20:00, Epoch 10/10]\n",
                     "    </div>\n",
                     "    <table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     " <tr style=\"text-align: left;\">\n",
                     "      <th>Epoch</th>\n",
                     "      <th>Training Loss</th>\n",
                     "      <th>Validation Loss</th>\n",
                     "      <th>Precision</th>\n",
                     "      <th>Recall</th>\n",
                     "      <th>F1</th>\n",
                     "      <th>Accuracy</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <td>1</td>\n",
                     "      <td>No log</td>\n",
                     "      <td>0.307435</td>\n",
                     "      <td>0.004621</td>\n",
                     "      <td>0.009782</td>\n",
                     "      <td>0.006277</td>\n",
                     "      <td>0.565764</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>2</td>\n",
                     "      <td>0.413400</td>\n",
                     "      <td>0.251194</td>\n",
                     "      <td>0.004732</td>\n",
                     "      <td>0.009782</td>\n",
                     "      <td>0.006379</td>\n",
                     "      <td>0.575791</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>3</td>\n",
                     "      <td>0.260700</td>\n",
                     "      <td>0.178076</td>\n",
                     "      <td>0.006151</td>\n",
                     "      <td>0.012792</td>\n",
                     "      <td>0.008307</td>\n",
                     "      <td>0.578331</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>4</td>\n",
                     "      <td>0.187500</td>\n",
                     "      <td>0.160181</td>\n",
                     "      <td>0.007221</td>\n",
                     "      <td>0.015801</td>\n",
                     "      <td>0.009913</td>\n",
                     "      <td>0.578591</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>5</td>\n",
                     "      <td>0.187500</td>\n",
                     "      <td>0.146192</td>\n",
                     "      <td>0.009019</td>\n",
                     "      <td>0.018811</td>\n",
                     "      <td>0.012192</td>\n",
                     "      <td>0.585298</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>6</td>\n",
                     "      <td>0.150800</td>\n",
                     "      <td>0.140893</td>\n",
                     "      <td>0.008291</td>\n",
                     "      <td>0.017306</td>\n",
                     "      <td>0.011211</td>\n",
                     "      <td>0.583670</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>7</td>\n",
                     "      <td>0.125500</td>\n",
                     "      <td>0.138360</td>\n",
                     "      <td>0.008636</td>\n",
                     "      <td>0.018059</td>\n",
                     "      <td>0.011685</td>\n",
                     "      <td>0.584842</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>8</td>\n",
                     "      <td>0.107900</td>\n",
                     "      <td>0.127260</td>\n",
                     "      <td>0.008003</td>\n",
                     "      <td>0.016554</td>\n",
                     "      <td>0.010790</td>\n",
                     "      <td>0.586795</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>9</td>\n",
                     "      <td>0.107900</td>\n",
                     "      <td>0.124863</td>\n",
                     "      <td>0.008727</td>\n",
                     "      <td>0.018059</td>\n",
                     "      <td>0.011768</td>\n",
                     "      <td>0.583865</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>10</td>\n",
                     "      <td>0.092800</td>\n",
                     "      <td>0.124522</td>\n",
                     "      <td>0.009390</td>\n",
                     "      <td>0.019564</td>\n",
                     "      <td>0.012689</td>\n",
                     "      <td>0.584060</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table><p>"
                  ],
                  "text/plain":[
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata":{
                  
               },
               "output_type":"display_data"
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "\n",
                  "\n",
                  "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
                  "\n",
                  "\n"
               ]
            },
            {
               "data":{
                  "text/plain":[
                     "TrainOutput(global_step=3810, training_loss=0.18261083818170343, metrics={'train_runtime': 4801.0518, 'train_samples_per_second': 6.342, 'train_steps_per_second': 0.794, 'total_flos': 7243268659200000.0, 'train_loss': 0.18261083818170343, 'epoch': 10.0})"
                  ]
               },
               "execution_count":18,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "from utils import Seq2SeqTrainerGenKwargs\n",
            "\n",
            "trainer = Seq2SeqTrainerGenKwargs(\n",
            "    model=model,\n",
            "    args=args,\n",
            "    train_dataset=training_set,\n",
            "    eval_dataset=val_set,\n",
            "    data_collator=data_collator,\n",
            "    compute_metrics=compute_metrics,\n",
            "    tokenizer=tokenizer,\n",
            "#     bad_words_ids=bad_words_ids,\n",
            "    force_words_ids=force_words_ids\n",
            ")\n",
            "trainer.train()"
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            
         },
         "source":[
            "# With control over logitsprocessor"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":12,
         "metadata":{
            
         },
         "outputs":[
            {
               "data":{
                  "text/plain":[
                     "tensor([517, 134,  27, 301, 272,  18, 254, 345, 411, 412])"
                  ]
               },
               "execution_count":12,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "# get possible ids of label tokens\n",
            "labelids = set()\n",
            "for thing in training_set:\n",
            "    labelids.update(thing['labels'].numpy())\n",
            "labelids.remove(tokenizer.eos_token_id)\n",
            "labelids.remove(-100)\n",
            "labelids = torch.LongTensor(list(labelids))\n",
            "labelids"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":13,
         "metadata":{
            
         },
         "outputs":[
            
         ],
         "source":[
            "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":14,
         "metadata":{
            
         },
         "outputs":[
            
         ],
         "source":[
            "from finetune import MyTrainer\n",
            "from transformers import Seq2SeqTrainingArguments, DataCollatorForSeq2Seq"
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            
         },
         "source":[
            "### learning_rate=5e-5, batch_size=8, weight_decay=1e-2"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":15,
         "metadata":{
            
         },
         "outputs":[
            
         ],
         "source":[
            "args = Seq2SeqTrainingArguments(\n",
            "    \"T5-pretrained-labelseq-ner-logitsprocessor\", evaluation_strategy=\"epoch\", save_strategy=\"epoch\",\n",
            "    learning_rate=5e-5, num_train_epochs=30, weight_decay=0.01, predict_with_generate=True,\n",
            "    per_device_train_batch_size=8, seed=7, #     no_cuda=True,\n",
            "    )\n",
            "\n",
            "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
            "trainer = MyTrainer(\n",
            "    model=model, args=args, train_dataset=training_set, eval_dataset=val_set,\n",
            "    data_collator=data_collator, compute_metrics=compute_metrics, tokenizer=tokenizer,\n",
            ")\n",
            "beamsz = 5"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":16,
         "metadata":{
            
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "/home/nanomineduke/anaconda3/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
                  "  FutureWarning,\n",
                  "***** Running training *****\n",
                  "  Num examples = 3045\n",
                  "  Num Epochs = 30\n",
                  "  Instantaneous batch size per device = 8\n",
                  "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
                  "  Gradient Accumulation steps = 1\n",
                  "  Total optimization steps = 11430\n"
               ]
            },
            {
               "data":{
                  "text/html":[
                     "\n",
                     "    <div>\n",
                     "      \n",
                     "      <progress value='11430' max='11430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                     "      [11430/11430 4:49:26, Epoch 30/30]\n",
                     "    </div>\n",
                     "    <table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     " <tr style=\"text-align: left;\">\n",
                     "      <th>Epoch</th>\n",
                     "      <th>Training Loss</th>\n",
                     "      <th>Validation Loss</th>\n",
                     "      <th>Precision</th>\n",
                     "      <th>Recall</th>\n",
                     "      <th>F1</th>\n",
                     "      <th>Accuracy</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <td>1</td>\n",
                     "      <td>No log</td>\n",
                     "      <td>0.307162</td>\n",
                     "      <td>0.124682</td>\n",
                     "      <td>0.073740</td>\n",
                     "      <td>0.092671</td>\n",
                     "      <td>0.623649</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>2</td>\n",
                     "      <td>0.472000</td>\n",
                     "      <td>0.271871</td>\n",
                     "      <td>0.143836</td>\n",
                     "      <td>0.094808</td>\n",
                     "      <td>0.114286</td>\n",
                     "      <td>0.600729</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>3</td>\n",
                     "      <td>0.304400</td>\n",
                     "      <td>0.224287</td>\n",
                     "      <td>0.211828</td>\n",
                     "      <td>0.148232</td>\n",
                     "      <td>0.174413</td>\n",
                     "      <td>0.680427</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>4</td>\n",
                     "      <td>0.243300</td>\n",
                     "      <td>0.215647</td>\n",
                     "      <td>0.247152</td>\n",
                     "      <td>0.212190</td>\n",
                     "      <td>0.228340</td>\n",
                     "      <td>0.702305</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>5</td>\n",
                     "      <td>0.243300</td>\n",
                     "      <td>0.170373</td>\n",
                     "      <td>0.313205</td>\n",
                     "      <td>0.292701</td>\n",
                     "      <td>0.302606</td>\n",
                     "      <td>0.732647</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>6</td>\n",
                     "      <td>0.195400</td>\n",
                     "      <td>0.161528</td>\n",
                     "      <td>0.362781</td>\n",
                     "      <td>0.376975</td>\n",
                     "      <td>0.369742</td>\n",
                     "      <td>0.758562</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>7</td>\n",
                     "      <td>0.164700</td>\n",
                     "      <td>0.145103</td>\n",
                     "      <td>0.409706</td>\n",
                     "      <td>0.387509</td>\n",
                     "      <td>0.398299</td>\n",
                     "      <td>0.775817</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>8</td>\n",
                     "      <td>0.142100</td>\n",
                     "      <td>0.149049</td>\n",
                     "      <td>0.352006</td>\n",
                     "      <td>0.349887</td>\n",
                     "      <td>0.350943</td>\n",
                     "      <td>0.749186</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>9</td>\n",
                     "      <td>0.142100</td>\n",
                     "      <td>0.140563</td>\n",
                     "      <td>0.468796</td>\n",
                     "      <td>0.474793</td>\n",
                     "      <td>0.471776</td>\n",
                     "      <td>0.802578</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>10</td>\n",
                     "      <td>0.123800</td>\n",
                     "      <td>0.126656</td>\n",
                     "      <td>0.511389</td>\n",
                     "      <td>0.523702</td>\n",
                     "      <td>0.517472</td>\n",
                     "      <td>0.818531</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>11</td>\n",
                     "      <td>0.110900</td>\n",
                     "      <td>0.122958</td>\n",
                     "      <td>0.486919</td>\n",
                     "      <td>0.504138</td>\n",
                     "      <td>0.495379</td>\n",
                     "      <td>0.811824</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>12</td>\n",
                     "      <td>0.099400</td>\n",
                     "      <td>0.134289</td>\n",
                     "      <td>0.488148</td>\n",
                     "      <td>0.495862</td>\n",
                     "      <td>0.491975</td>\n",
                     "      <td>0.818075</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>13</td>\n",
                     "      <td>0.099400</td>\n",
                     "      <td>0.125805</td>\n",
                     "      <td>0.516200</td>\n",
                     "      <td>0.527464</td>\n",
                     "      <td>0.521771</td>\n",
                     "      <td>0.824196</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>14</td>\n",
                     "      <td>0.089900</td>\n",
                     "      <td>0.122278</td>\n",
                     "      <td>0.566810</td>\n",
                     "      <td>0.593679</td>\n",
                     "      <td>0.579934</td>\n",
                     "      <td>0.838521</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>15</td>\n",
                     "      <td>0.084100</td>\n",
                     "      <td>0.132117</td>\n",
                     "      <td>0.562900</td>\n",
                     "      <td>0.595937</td>\n",
                     "      <td>0.578947</td>\n",
                     "      <td>0.839107</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>16</td>\n",
                     "      <td>0.076600</td>\n",
                     "      <td>0.128025</td>\n",
                     "      <td>0.543586</td>\n",
                     "      <td>0.577126</td>\n",
                     "      <td>0.559854</td>\n",
                     "      <td>0.841776</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>17</td>\n",
                     "      <td>0.076600</td>\n",
                     "      <td>0.122630</td>\n",
                     "      <td>0.566790</td>\n",
                     "      <td>0.577878</td>\n",
                     "      <td>0.572280</td>\n",
                     "      <td>0.846139</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>18</td>\n",
                     "      <td>0.072100</td>\n",
                     "      <td>0.151193</td>\n",
                     "      <td>0.532421</td>\n",
                     "      <td>0.556057</td>\n",
                     "      <td>0.543982</td>\n",
                     "      <td>0.828038</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>19</td>\n",
                     "      <td>0.066300</td>\n",
                     "      <td>0.129827</td>\n",
                     "      <td>0.561555</td>\n",
                     "      <td>0.586907</td>\n",
                     "      <td>0.573951</td>\n",
                     "      <td>0.843079</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>20</td>\n",
                     "      <td>0.062200</td>\n",
                     "      <td>0.127534</td>\n",
                     "      <td>0.584294</td>\n",
                     "      <td>0.610233</td>\n",
                     "      <td>0.596982</td>\n",
                     "      <td>0.846269</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>21</td>\n",
                     "      <td>0.058800</td>\n",
                     "      <td>0.125042</td>\n",
                     "      <td>0.568953</td>\n",
                     "      <td>0.592927</td>\n",
                     "      <td>0.580693</td>\n",
                     "      <td>0.845097</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>22</td>\n",
                     "      <td>0.058800</td>\n",
                     "      <td>0.128039</td>\n",
                     "      <td>0.596045</td>\n",
                     "      <td>0.635064</td>\n",
                     "      <td>0.614936</td>\n",
                     "      <td>0.852520</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>23</td>\n",
                     "      <td>0.054900</td>\n",
                     "      <td>0.126731</td>\n",
                     "      <td>0.600846</td>\n",
                     "      <td>0.641084</td>\n",
                     "      <td>0.620313</td>\n",
                     "      <td>0.858966</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>24</td>\n",
                     "      <td>0.051500</td>\n",
                     "      <td>0.134840</td>\n",
                     "      <td>0.569513</td>\n",
                     "      <td>0.607223</td>\n",
                     "      <td>0.587764</td>\n",
                     "      <td>0.846855</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>25</td>\n",
                     "      <td>0.049500</td>\n",
                     "      <td>0.142062</td>\n",
                     "      <td>0.568794</td>\n",
                     "      <td>0.603461</td>\n",
                     "      <td>0.585615</td>\n",
                     "      <td>0.847636</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>26</td>\n",
                     "      <td>0.049500</td>\n",
                     "      <td>0.131683</td>\n",
                     "      <td>0.602436</td>\n",
                     "      <td>0.632807</td>\n",
                     "      <td>0.617248</td>\n",
                     "      <td>0.856687</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>27</td>\n",
                     "      <td>0.047800</td>\n",
                     "      <td>0.138518</td>\n",
                     "      <td>0.604435</td>\n",
                     "      <td>0.635816</td>\n",
                     "      <td>0.619729</td>\n",
                     "      <td>0.857729</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>28</td>\n",
                     "      <td>0.046200</td>\n",
                     "      <td>0.134965</td>\n",
                     "      <td>0.606277</td>\n",
                     "      <td>0.639579</td>\n",
                     "      <td>0.622483</td>\n",
                     "      <td>0.858120</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>29</td>\n",
                     "      <td>0.044500</td>\n",
                     "      <td>0.135753</td>\n",
                     "      <td>0.605544</td>\n",
                     "      <td>0.641084</td>\n",
                     "      <td>0.622807</td>\n",
                     "      <td>0.858966</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>30</td>\n",
                     "      <td>0.044500</td>\n",
                     "      <td>0.135365</td>\n",
                     "      <td>0.599859</td>\n",
                     "      <td>0.639579</td>\n",
                     "      <td>0.619082</td>\n",
                     "      <td>0.858185</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table><p>"
                  ],
                  "text/plain":[
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata":{
                  
               },
               "output_type":"display_data"
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "\n",
                  "\n",
                  "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
                  "\n",
                  "\n"
               ]
            },
            {
               "data":{
                  "text/plain":[
                     "TrainOutput(global_step=11430, training_loss=0.11802315165468819, metrics={'train_runtime': 17367.7344, 'train_samples_per_second': 5.26, 'train_steps_per_second': 0.658, 'total_flos': 2.17298059776e+16, 'train_loss': 0.11802315165468819, 'epoch': 30.0})"
                  ]
               },
               "execution_count":16,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "trainer.set_things(labelids, tokenizer, beamsz)\n",
            "trainer.train()"
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            
         },
         "source":[
            "### learning_rate=1e-4, batch_size=8, weight_decay=1e-2"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":17,
         "metadata":{
            
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "PyTorch: setting up devices\n",
                  "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
               ]
            }
         ],
         "source":[
            "args = Seq2SeqTrainingArguments(\n",
            "    \"T5-pretrained-labelseq-ner-logitsprocessor-lr1e-4\", evaluation_strategy=\"epoch\", save_strategy=\"epoch\",\n",
            "    learning_rate=1e-4, num_train_epochs=30, weight_decay=0.01, predict_with_generate=True,\n",
            "    per_device_train_batch_size=8, seed=7, #     no_cuda=True,\n",
            "    )\n",
            "\n",
            "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
            "trainer = MyTrainer(\n",
            "    model=model, args=args, train_dataset=training_set, eval_dataset=val_set,\n",
            "    data_collator=data_collator, compute_metrics=compute_metrics, tokenizer=tokenizer,\n",
            ")\n",
            "beamsz = 5"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":18,
         "metadata":{
            "scrolled":true
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "/home/nanomineduke/anaconda3/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
                  "  FutureWarning,\n",
                  "***** Running training *****\n",
                  "  Num examples = 3045\n",
                  "  Num Epochs = 30\n",
                  "  Instantaneous batch size per device = 8\n",
                  "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
                  "  Gradient Accumulation steps = 1\n",
                  "  Total optimization steps = 11430\n"
               ]
            },
            {
               "data":{
                  "text/html":[
                     "\n",
                     "    <div>\n",
                     "      \n",
                     "      <progress value='11430' max='11430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                     "      [11430/11430 4:49:58, Epoch 30/30]\n",
                     "    </div>\n",
                     "    <table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     " <tr style=\"text-align: left;\">\n",
                     "      <th>Epoch</th>\n",
                     "      <th>Training Loss</th>\n",
                     "      <th>Validation Loss</th>\n",
                     "      <th>Precision</th>\n",
                     "      <th>Recall</th>\n",
                     "      <th>F1</th>\n",
                     "      <th>Accuracy</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <td>1</td>\n",
                     "      <td>No log</td>\n",
                     "      <td>0.151111</td>\n",
                     "      <td>0.503084</td>\n",
                     "      <td>0.552295</td>\n",
                     "      <td>0.526542</td>\n",
                     "      <td>0.815341</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>2</td>\n",
                     "      <td>0.086900</td>\n",
                     "      <td>0.140965</td>\n",
                     "      <td>0.456781</td>\n",
                     "      <td>0.489090</td>\n",
                     "      <td>0.472384</td>\n",
                     "      <td>0.799909</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>3</td>\n",
                     "      <td>0.077800</td>\n",
                     "      <td>0.134222</td>\n",
                     "      <td>0.590701</td>\n",
                     "      <td>0.583145</td>\n",
                     "      <td>0.586899</td>\n",
                     "      <td>0.835525</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>4</td>\n",
                     "      <td>0.070300</td>\n",
                     "      <td>0.143641</td>\n",
                     "      <td>0.502505</td>\n",
                     "      <td>0.528217</td>\n",
                     "      <td>0.515040</td>\n",
                     "      <td>0.812801</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>5</td>\n",
                     "      <td>0.070300</td>\n",
                     "      <td>0.137537</td>\n",
                     "      <td>0.560320</td>\n",
                     "      <td>0.580135</td>\n",
                     "      <td>0.570055</td>\n",
                     "      <td>0.838651</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>6</td>\n",
                     "      <td>0.059900</td>\n",
                     "      <td>0.134703</td>\n",
                     "      <td>0.576379</td>\n",
                     "      <td>0.613243</td>\n",
                     "      <td>0.594240</td>\n",
                     "      <td>0.849590</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>7</td>\n",
                     "      <td>0.053500</td>\n",
                     "      <td>0.134402</td>\n",
                     "      <td>0.607349</td>\n",
                     "      <td>0.634312</td>\n",
                     "      <td>0.620537</td>\n",
                     "      <td>0.859422</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>8</td>\n",
                     "      <td>0.050200</td>\n",
                     "      <td>0.138921</td>\n",
                     "      <td>0.613201</td>\n",
                     "      <td>0.650113</td>\n",
                     "      <td>0.631118</td>\n",
                     "      <td>0.858380</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>9</td>\n",
                     "      <td>0.050200</td>\n",
                     "      <td>0.138878</td>\n",
                     "      <td>0.593772</td>\n",
                     "      <td>0.645598</td>\n",
                     "      <td>0.618601</td>\n",
                     "      <td>0.855255</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>10</td>\n",
                     "      <td>0.043200</td>\n",
                     "      <td>0.136779</td>\n",
                     "      <td>0.603175</td>\n",
                     "      <td>0.629044</td>\n",
                     "      <td>0.615838</td>\n",
                     "      <td>0.849394</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>11</td>\n",
                     "      <td>0.042100</td>\n",
                     "      <td>0.140921</td>\n",
                     "      <td>0.604749</td>\n",
                     "      <td>0.651618</td>\n",
                     "      <td>0.627309</td>\n",
                     "      <td>0.853236</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>12</td>\n",
                     "      <td>0.039300</td>\n",
                     "      <td>0.147459</td>\n",
                     "      <td>0.606734</td>\n",
                     "      <td>0.637321</td>\n",
                     "      <td>0.621651</td>\n",
                     "      <td>0.855775</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>13</td>\n",
                     "      <td>0.039300</td>\n",
                     "      <td>0.134869</td>\n",
                     "      <td>0.638223</td>\n",
                     "      <td>0.680963</td>\n",
                     "      <td>0.658901</td>\n",
                     "      <td>0.865477</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>14</td>\n",
                     "      <td>0.037100</td>\n",
                     "      <td>0.148810</td>\n",
                     "      <td>0.630480</td>\n",
                     "      <td>0.681716</td>\n",
                     "      <td>0.655098</td>\n",
                     "      <td>0.867040</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>15</td>\n",
                     "      <td>0.033000</td>\n",
                     "      <td>0.138728</td>\n",
                     "      <td>0.640146</td>\n",
                     "      <td>0.659895</td>\n",
                     "      <td>0.649870</td>\n",
                     "      <td>0.869644</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>16</td>\n",
                     "      <td>0.031100</td>\n",
                     "      <td>0.162165</td>\n",
                     "      <td>0.595376</td>\n",
                     "      <td>0.620015</td>\n",
                     "      <td>0.607446</td>\n",
                     "      <td>0.858380</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>17</td>\n",
                     "      <td>0.031100</td>\n",
                     "      <td>0.144324</td>\n",
                     "      <td>0.644476</td>\n",
                     "      <td>0.684725</td>\n",
                     "      <td>0.663991</td>\n",
                     "      <td>0.871923</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>18</td>\n",
                     "      <td>0.028800</td>\n",
                     "      <td>0.161963</td>\n",
                     "      <td>0.634535</td>\n",
                     "      <td>0.688488</td>\n",
                     "      <td>0.660411</td>\n",
                     "      <td>0.869254</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>19</td>\n",
                     "      <td>0.027500</td>\n",
                     "      <td>0.166298</td>\n",
                     "      <td>0.650036</td>\n",
                     "      <td>0.686230</td>\n",
                     "      <td>0.667643</td>\n",
                     "      <td>0.874137</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>20</td>\n",
                     "      <td>0.024400</td>\n",
                     "      <td>0.161776</td>\n",
                     "      <td>0.660297</td>\n",
                     "      <td>0.702032</td>\n",
                     "      <td>0.680525</td>\n",
                     "      <td>0.878695</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>21</td>\n",
                     "      <td>0.023200</td>\n",
                     "      <td>0.157790</td>\n",
                     "      <td>0.636491</td>\n",
                     "      <td>0.682468</td>\n",
                     "      <td>0.658678</td>\n",
                     "      <td>0.875635</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>22</td>\n",
                     "      <td>0.023200</td>\n",
                     "      <td>0.170624</td>\n",
                     "      <td>0.609123</td>\n",
                     "      <td>0.653123</td>\n",
                     "      <td>0.630356</td>\n",
                     "      <td>0.859226</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>23</td>\n",
                     "      <td>0.022200</td>\n",
                     "      <td>0.165356</td>\n",
                     "      <td>0.672585</td>\n",
                     "      <td>0.712566</td>\n",
                     "      <td>0.691999</td>\n",
                     "      <td>0.883709</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>24</td>\n",
                     "      <td>0.020200</td>\n",
                     "      <td>0.157767</td>\n",
                     "      <td>0.670029</td>\n",
                     "      <td>0.699774</td>\n",
                     "      <td>0.684579</td>\n",
                     "      <td>0.878435</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>25</td>\n",
                     "      <td>0.019000</td>\n",
                     "      <td>0.171695</td>\n",
                     "      <td>0.652205</td>\n",
                     "      <td>0.689992</td>\n",
                     "      <td>0.670567</td>\n",
                     "      <td>0.878239</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>26</td>\n",
                     "      <td>0.019000</td>\n",
                     "      <td>0.168316</td>\n",
                     "      <td>0.676868</td>\n",
                     "      <td>0.715576</td>\n",
                     "      <td>0.695684</td>\n",
                     "      <td>0.887355</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>27</td>\n",
                     "      <td>0.018300</td>\n",
                     "      <td>0.175878</td>\n",
                     "      <td>0.676613</td>\n",
                     "      <td>0.733634</td>\n",
                     "      <td>0.703971</td>\n",
                     "      <td>0.887355</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>28</td>\n",
                     "      <td>0.016700</td>\n",
                     "      <td>0.176588</td>\n",
                     "      <td>0.678420</td>\n",
                     "      <td>0.723853</td>\n",
                     "      <td>0.700400</td>\n",
                     "      <td>0.888267</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>29</td>\n",
                     "      <td>0.015200</td>\n",
                     "      <td>0.180337</td>\n",
                     "      <td>0.673427</td>\n",
                     "      <td>0.724605</td>\n",
                     "      <td>0.698079</td>\n",
                     "      <td>0.888136</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>30</td>\n",
                     "      <td>0.015200</td>\n",
                     "      <td>0.178991</td>\n",
                     "      <td>0.676782</td>\n",
                     "      <td>0.721595</td>\n",
                     "      <td>0.698471</td>\n",
                     "      <td>0.888071</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table><p>"
                  ],
                  "text/plain":[
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata":{
                  
               },
               "output_type":"display_data"
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "\n",
                  "\n",
                  "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
                  "\n",
                  "\n"
               ]
            },
            {
               "data":{
                  "text/plain":[
                     "TrainOutput(global_step=11430, training_loss=0.0372927551403029, metrics={'train_runtime': 17398.8882, 'train_samples_per_second': 5.25, 'train_steps_per_second': 0.657, 'total_flos': 2.17298059776e+16, 'train_loss': 0.0372927551403029, 'epoch': 30.0})"
                  ]
               },
               "execution_count":18,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "trainer.set_things(labelids, tokenizer, beamsz)\n",
            "trainer.train()"
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            
         },
         "source":[
            "### learning_rate=2e-4, batch_size=8, weight_decay=1e-2"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":19,
         "metadata":{
            
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "PyTorch: setting up devices\n",
                  "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
               ]
            }
         ],
         "source":[
            "args = Seq2SeqTrainingArguments(\n",
            "    \"T5-pretrained-labelseq-ner-logitsprocessor-lr2e-4\", evaluation_strategy=\"epoch\", save_strategy=\"epoch\",\n",
            "    learning_rate=2e-4, num_train_epochs=30, weight_decay=0.01, predict_with_generate=True,\n",
            "    per_device_train_batch_size=8, seed=7, #     no_cuda=True,\n",
            "    )\n",
            "\n",
            "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
            "trainer = MyTrainer(\n",
            "    model=model, args=args, train_dataset=training_set, eval_dataset=val_set,\n",
            "    data_collator=data_collator, compute_metrics=compute_metrics, tokenizer=tokenizer,\n",
            ")\n",
            "beamsz = 5"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":20,
         "metadata":{
            "scrolled":true
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "/home/nanomineduke/anaconda3/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
                  "  FutureWarning,\n",
                  "***** Running training *****\n",
                  "  Num examples = 3045\n",
                  "  Num Epochs = 30\n",
                  "  Instantaneous batch size per device = 8\n",
                  "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
                  "  Gradient Accumulation steps = 1\n",
                  "  Total optimization steps = 11430\n"
               ]
            },
            {
               "data":{
                  "text/html":[
                     "\n",
                     "    <div>\n",
                     "      \n",
                     "      <progress value='11430' max='11430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                     "      [11430/11430 4:45:18, Epoch 30/30]\n",
                     "    </div>\n",
                     "    <table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     " <tr style=\"text-align: left;\">\n",
                     "      <th>Epoch</th>\n",
                     "      <th>Training Loss</th>\n",
                     "      <th>Validation Loss</th>\n",
                     "      <th>Precision</th>\n",
                     "      <th>Recall</th>\n",
                     "      <th>F1</th>\n",
                     "      <th>Accuracy</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <td>1</td>\n",
                     "      <td>No log</td>\n",
                     "      <td>0.147819</td>\n",
                     "      <td>0.553282</td>\n",
                     "      <td>0.589917</td>\n",
                     "      <td>0.571012</td>\n",
                     "      <td>0.830707</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>2</td>\n",
                     "      <td>0.058200</td>\n",
                     "      <td>0.134215</td>\n",
                     "      <td>0.585851</td>\n",
                     "      <td>0.598194</td>\n",
                     "      <td>0.591958</td>\n",
                     "      <td>0.842948</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>3</td>\n",
                     "      <td>0.055100</td>\n",
                     "      <td>0.133107</td>\n",
                     "      <td>0.587554</td>\n",
                     "      <td>0.610986</td>\n",
                     "      <td>0.599041</td>\n",
                     "      <td>0.843795</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>4</td>\n",
                     "      <td>0.050200</td>\n",
                     "      <td>0.140343</td>\n",
                     "      <td>0.606856</td>\n",
                     "      <td>0.626035</td>\n",
                     "      <td>0.616296</td>\n",
                     "      <td>0.855645</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>5</td>\n",
                     "      <td>0.050200</td>\n",
                     "      <td>0.143708</td>\n",
                     "      <td>0.593772</td>\n",
                     "      <td>0.631302</td>\n",
                     "      <td>0.611962</td>\n",
                     "      <td>0.849590</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>6</td>\n",
                     "      <td>0.044800</td>\n",
                     "      <td>0.153496</td>\n",
                     "      <td>0.600678</td>\n",
                     "      <td>0.666667</td>\n",
                     "      <td>0.631954</td>\n",
                     "      <td>0.853106</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>7</td>\n",
                     "      <td>0.039500</td>\n",
                     "      <td>0.167229</td>\n",
                     "      <td>0.611860</td>\n",
                     "      <td>0.683220</td>\n",
                     "      <td>0.645574</td>\n",
                     "      <td>0.860854</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>8</td>\n",
                     "      <td>0.035700</td>\n",
                     "      <td>0.137771</td>\n",
                     "      <td>0.641993</td>\n",
                     "      <td>0.678706</td>\n",
                     "      <td>0.659839</td>\n",
                     "      <td>0.868603</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>9</td>\n",
                     "      <td>0.035700</td>\n",
                     "      <td>0.163840</td>\n",
                     "      <td>0.582332</td>\n",
                     "      <td>0.620015</td>\n",
                     "      <td>0.600583</td>\n",
                     "      <td>0.848613</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>10</td>\n",
                     "      <td>0.032400</td>\n",
                     "      <td>0.154596</td>\n",
                     "      <td>0.646817</td>\n",
                     "      <td>0.711061</td>\n",
                     "      <td>0.677419</td>\n",
                     "      <td>0.869124</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>11</td>\n",
                     "      <td>0.031200</td>\n",
                     "      <td>0.137784</td>\n",
                     "      <td>0.631693</td>\n",
                     "      <td>0.656885</td>\n",
                     "      <td>0.644043</td>\n",
                     "      <td>0.862352</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>12</td>\n",
                     "      <td>0.028300</td>\n",
                     "      <td>0.161861</td>\n",
                     "      <td>0.630612</td>\n",
                     "      <td>0.697517</td>\n",
                     "      <td>0.662379</td>\n",
                     "      <td>0.865803</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>13</td>\n",
                     "      <td>0.028300</td>\n",
                     "      <td>0.152192</td>\n",
                     "      <td>0.643156</td>\n",
                     "      <td>0.693002</td>\n",
                     "      <td>0.667150</td>\n",
                     "      <td>0.870361</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>14</td>\n",
                     "      <td>0.027000</td>\n",
                     "      <td>0.162145</td>\n",
                     "      <td>0.675920</td>\n",
                     "      <td>0.732882</td>\n",
                     "      <td>0.703249</td>\n",
                     "      <td>0.881951</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>15</td>\n",
                     "      <td>0.024400</td>\n",
                     "      <td>0.149438</td>\n",
                     "      <td>0.602410</td>\n",
                     "      <td>0.639579</td>\n",
                     "      <td>0.620438</td>\n",
                     "      <td>0.857078</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>16</td>\n",
                     "      <td>0.024400</td>\n",
                     "      <td>0.166517</td>\n",
                     "      <td>0.659075</td>\n",
                     "      <td>0.696764</td>\n",
                     "      <td>0.677396</td>\n",
                     "      <td>0.874398</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>17</td>\n",
                     "      <td>0.024400</td>\n",
                     "      <td>0.143093</td>\n",
                     "      <td>0.710315</td>\n",
                     "      <td>0.730625</td>\n",
                     "      <td>0.720326</td>\n",
                     "      <td>0.893997</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>18</td>\n",
                     "      <td>0.020800</td>\n",
                     "      <td>0.156088</td>\n",
                     "      <td>0.653231</td>\n",
                     "      <td>0.707299</td>\n",
                     "      <td>0.679191</td>\n",
                     "      <td>0.880649</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>19</td>\n",
                     "      <td>0.019700</td>\n",
                     "      <td>0.166678</td>\n",
                     "      <td>0.666902</td>\n",
                     "      <td>0.709556</td>\n",
                     "      <td>0.687568</td>\n",
                     "      <td>0.881625</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>20</td>\n",
                     "      <td>0.018300</td>\n",
                     "      <td>0.168891</td>\n",
                     "      <td>0.715208</td>\n",
                     "      <td>0.750188</td>\n",
                     "      <td>0.732281</td>\n",
                     "      <td>0.898750</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>21</td>\n",
                     "      <td>0.016800</td>\n",
                     "      <td>0.159448</td>\n",
                     "      <td>0.705072</td>\n",
                     "      <td>0.732129</td>\n",
                     "      <td>0.718346</td>\n",
                     "      <td>0.891327</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>22</td>\n",
                     "      <td>0.016800</td>\n",
                     "      <td>0.165755</td>\n",
                     "      <td>0.713877</td>\n",
                     "      <td>0.750941</td>\n",
                     "      <td>0.731940</td>\n",
                     "      <td>0.896601</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>23</td>\n",
                     "      <td>0.015500</td>\n",
                     "      <td>0.181679</td>\n",
                     "      <td>0.711400</td>\n",
                     "      <td>0.741911</td>\n",
                     "      <td>0.726335</td>\n",
                     "      <td>0.894518</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>24</td>\n",
                     "      <td>0.013800</td>\n",
                     "      <td>0.178715</td>\n",
                     "      <td>0.711143</td>\n",
                     "      <td>0.753950</td>\n",
                     "      <td>0.731921</td>\n",
                     "      <td>0.892173</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>25</td>\n",
                     "      <td>0.012600</td>\n",
                     "      <td>0.179985</td>\n",
                     "      <td>0.676096</td>\n",
                     "      <td>0.719338</td>\n",
                     "      <td>0.697047</td>\n",
                     "      <td>0.885662</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>26</td>\n",
                     "      <td>0.012600</td>\n",
                     "      <td>0.184775</td>\n",
                     "      <td>0.686219</td>\n",
                     "      <td>0.730625</td>\n",
                     "      <td>0.707726</td>\n",
                     "      <td>0.889374</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>27</td>\n",
                     "      <td>0.011100</td>\n",
                     "      <td>0.191177</td>\n",
                     "      <td>0.717730</td>\n",
                     "      <td>0.761475</td>\n",
                     "      <td>0.738956</td>\n",
                     "      <td>0.898945</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>28</td>\n",
                     "      <td>0.009900</td>\n",
                     "      <td>0.192300</td>\n",
                     "      <td>0.713043</td>\n",
                     "      <td>0.740406</td>\n",
                     "      <td>0.726467</td>\n",
                     "      <td>0.897448</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>29</td>\n",
                     "      <td>0.009100</td>\n",
                     "      <td>0.195089</td>\n",
                     "      <td>0.710155</td>\n",
                     "      <td>0.757713</td>\n",
                     "      <td>0.733163</td>\n",
                     "      <td>0.897122</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>30</td>\n",
                     "      <td>0.009100</td>\n",
                     "      <td>0.195020</td>\n",
                     "      <td>0.715700</td>\n",
                     "      <td>0.761475</td>\n",
                     "      <td>0.737878</td>\n",
                     "      <td>0.899141</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table><p>"
                  ],
                  "text/plain":[
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata":{
                  
               },
               "output_type":"display_data"
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "\n",
                  "\n",
                  "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
                  "\n",
                  "\n"
               ]
            },
            {
               "data":{
                  "text/plain":[
                     "TrainOutput(global_step=11430, training_loss=0.026494044644313222, metrics={'train_runtime': 17118.9298, 'train_samples_per_second': 5.336, 'train_steps_per_second': 0.668, 'total_flos': 2.17298059776e+16, 'train_loss': 0.026494044644313222, 'epoch': 30.0})"
                  ]
               },
               "execution_count":20,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "trainer.set_things(labelids, tokenizer, beamsz)\n",
            "trainer.train()"
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            
         },
         "source":[
            "### learning_rate=1e-4, batch_size=16, weight_decay=1e-2"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":21,
         "metadata":{
            
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "PyTorch: setting up devices\n",
                  "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
               ]
            }
         ],
         "source":[
            "args = Seq2SeqTrainingArguments(\n",
            "    \"T5-pretrained-labelseq-ner-logitsprocessor-lr1e-4-batch-16\", evaluation_strategy=\"epoch\", save_strategy=\"epoch\",\n",
            "    learning_rate=1e-4, num_train_epochs=40, weight_decay=0.01, predict_with_generate=True,\n",
            "    per_device_train_batch_size=16, seed=7, #     no_cuda=True,\n",
            "    )\n",
            "\n",
            "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
            "trainer = MyTrainer(\n",
            "    model=model, args=args, train_dataset=training_set, eval_dataset=val_set,\n",
            "    data_collator=data_collator, compute_metrics=compute_metrics, tokenizer=tokenizer,\n",
            ")\n",
            "beamsz = 5"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":22,
         "metadata":{
            "scrolled":true
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "/home/nanomineduke/anaconda3/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
                  "  FutureWarning,\n",
                  "***** Running training *****\n",
                  "  Num examples = 3045\n",
                  "  Num Epochs = 40\n",
                  "  Instantaneous batch size per device = 16\n",
                  "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
                  "  Gradient Accumulation steps = 1\n",
                  "  Total optimization steps = 7640\n"
               ]
            },
            {
               "data":{
                  "text/html":[
                     "\n",
                     "    <div>\n",
                     "      \n",
                     "      <progress value='7640' max='7640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                     "      [7640/7640 6:10:35, Epoch 40/40]\n",
                     "    </div>\n",
                     "    <table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     " <tr style=\"text-align: left;\">\n",
                     "      <th>Epoch</th>\n",
                     "      <th>Training Loss</th>\n",
                     "      <th>Validation Loss</th>\n",
                     "      <th>Precision</th>\n",
                     "      <th>Recall</th>\n",
                     "      <th>F1</th>\n",
                     "      <th>Accuracy</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <td>1</td>\n",
                     "      <td>No log</td>\n",
                     "      <td>0.189311</td>\n",
                     "      <td>0.679639</td>\n",
                     "      <td>0.735892</td>\n",
                     "      <td>0.706647</td>\n",
                     "      <td>0.887290</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>2</td>\n",
                     "      <td>No log</td>\n",
                     "      <td>0.160540</td>\n",
                     "      <td>0.659816</td>\n",
                     "      <td>0.700527</td>\n",
                     "      <td>0.679562</td>\n",
                     "      <td>0.879281</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>3</td>\n",
                     "      <td>0.016000</td>\n",
                     "      <td>0.167983</td>\n",
                     "      <td>0.698368</td>\n",
                     "      <td>0.740406</td>\n",
                     "      <td>0.718773</td>\n",
                     "      <td>0.889960</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>4</td>\n",
                     "      <td>0.016000</td>\n",
                     "      <td>0.184332</td>\n",
                     "      <td>0.691197</td>\n",
                     "      <td>0.756208</td>\n",
                     "      <td>0.722242</td>\n",
                     "      <td>0.891001</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>5</td>\n",
                     "      <td>0.016000</td>\n",
                     "      <td>0.171497</td>\n",
                     "      <td>0.723110</td>\n",
                     "      <td>0.748683</td>\n",
                     "      <td>0.735675</td>\n",
                     "      <td>0.897252</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>6</td>\n",
                     "      <td>0.015400</td>\n",
                     "      <td>0.180105</td>\n",
                     "      <td>0.706847</td>\n",
                     "      <td>0.745673</td>\n",
                     "      <td>0.725741</td>\n",
                     "      <td>0.892043</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>7</td>\n",
                     "      <td>0.015400</td>\n",
                     "      <td>0.175856</td>\n",
                     "      <td>0.710014</td>\n",
                     "      <td>0.768247</td>\n",
                     "      <td>0.737983</td>\n",
                     "      <td>0.900703</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>8</td>\n",
                     "      <td>0.013800</td>\n",
                     "      <td>0.162801</td>\n",
                     "      <td>0.727338</td>\n",
                     "      <td>0.760722</td>\n",
                     "      <td>0.743656</td>\n",
                     "      <td>0.899987</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>9</td>\n",
                     "      <td>0.013800</td>\n",
                     "      <td>0.188710</td>\n",
                     "      <td>0.661660</td>\n",
                     "      <td>0.696012</td>\n",
                     "      <td>0.678401</td>\n",
                     "      <td>0.873681</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>10</td>\n",
                     "      <td>0.013800</td>\n",
                     "      <td>0.181263</td>\n",
                     "      <td>0.717407</td>\n",
                     "      <td>0.765989</td>\n",
                     "      <td>0.740902</td>\n",
                     "      <td>0.893997</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>11</td>\n",
                     "      <td>0.013100</td>\n",
                     "      <td>0.183348</td>\n",
                     "      <td>0.700915</td>\n",
                     "      <td>0.749436</td>\n",
                     "      <td>0.724364</td>\n",
                     "      <td>0.891718</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>12</td>\n",
                     "      <td>0.013100</td>\n",
                     "      <td>0.177844</td>\n",
                     "      <td>0.702532</td>\n",
                     "      <td>0.751693</td>\n",
                     "      <td>0.726281</td>\n",
                     "      <td>0.893736</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>13</td>\n",
                     "      <td>0.013100</td>\n",
                     "      <td>0.204284</td>\n",
                     "      <td>0.685378</td>\n",
                     "      <td>0.744169</td>\n",
                     "      <td>0.713564</td>\n",
                     "      <td>0.888462</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>14</td>\n",
                     "      <td>0.011900</td>\n",
                     "      <td>0.167801</td>\n",
                     "      <td>0.684173</td>\n",
                     "      <td>0.725357</td>\n",
                     "      <td>0.704164</td>\n",
                     "      <td>0.885076</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>15</td>\n",
                     "      <td>0.011900</td>\n",
                     "      <td>0.168576</td>\n",
                     "      <td>0.707714</td>\n",
                     "      <td>0.752445</td>\n",
                     "      <td>0.729395</td>\n",
                     "      <td>0.891522</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>16</td>\n",
                     "      <td>0.011800</td>\n",
                     "      <td>0.182395</td>\n",
                     "      <td>0.723896</td>\n",
                     "      <td>0.777276</td>\n",
                     "      <td>0.749637</td>\n",
                     "      <td>0.900378</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>17</td>\n",
                     "      <td>0.011800</td>\n",
                     "      <td>0.179876</td>\n",
                     "      <td>0.731461</td>\n",
                     "      <td>0.764485</td>\n",
                     "      <td>0.747609</td>\n",
                     "      <td>0.902005</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>18</td>\n",
                     "      <td>0.011800</td>\n",
                     "      <td>0.198501</td>\n",
                     "      <td>0.711471</td>\n",
                     "      <td>0.760722</td>\n",
                     "      <td>0.735273</td>\n",
                     "      <td>0.896731</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>19</td>\n",
                     "      <td>0.010300</td>\n",
                     "      <td>0.197128</td>\n",
                     "      <td>0.708950</td>\n",
                     "      <td>0.756960</td>\n",
                     "      <td>0.732169</td>\n",
                     "      <td>0.892043</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>20</td>\n",
                     "      <td>0.010300</td>\n",
                     "      <td>0.190934</td>\n",
                     "      <td>0.720363</td>\n",
                     "      <td>0.777276</td>\n",
                     "      <td>0.747738</td>\n",
                     "      <td>0.900117</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>21</td>\n",
                     "      <td>0.010400</td>\n",
                     "      <td>0.196051</td>\n",
                     "      <td>0.691146</td>\n",
                     "      <td>0.757713</td>\n",
                     "      <td>0.722900</td>\n",
                     "      <td>0.893541</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>22</td>\n",
                     "      <td>0.010400</td>\n",
                     "      <td>0.207459</td>\n",
                     "      <td>0.718728</td>\n",
                     "      <td>0.782543</td>\n",
                     "      <td>0.749280</td>\n",
                     "      <td>0.900182</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>23</td>\n",
                     "      <td>0.010400</td>\n",
                     "      <td>0.200914</td>\n",
                     "      <td>0.720200</td>\n",
                     "      <td>0.759217</td>\n",
                     "      <td>0.739194</td>\n",
                     "      <td>0.897187</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>24</td>\n",
                     "      <td>0.008600</td>\n",
                     "      <td>0.199319</td>\n",
                     "      <td>0.699504</td>\n",
                     "      <td>0.742664</td>\n",
                     "      <td>0.720438</td>\n",
                     "      <td>0.894583</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>25</td>\n",
                     "      <td>0.008600</td>\n",
                     "      <td>0.214698</td>\n",
                     "      <td>0.715390</td>\n",
                     "      <td>0.765989</td>\n",
                     "      <td>0.739826</td>\n",
                     "      <td>0.899336</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>26</td>\n",
                     "      <td>0.008600</td>\n",
                     "      <td>0.208357</td>\n",
                     "      <td>0.709205</td>\n",
                     "      <td>0.765237</td>\n",
                     "      <td>0.736156</td>\n",
                     "      <td>0.900313</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>27</td>\n",
                     "      <td>0.008600</td>\n",
                     "      <td>0.208320</td>\n",
                     "      <td>0.718596</td>\n",
                     "      <td>0.770504</td>\n",
                     "      <td>0.743646</td>\n",
                     "      <td>0.902722</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>28</td>\n",
                     "      <td>0.008600</td>\n",
                     "      <td>0.213645</td>\n",
                     "      <td>0.728491</td>\n",
                     "      <td>0.777276</td>\n",
                     "      <td>0.752093</td>\n",
                     "      <td>0.903829</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>29</td>\n",
                     "      <td>0.007700</td>\n",
                     "      <td>0.212721</td>\n",
                     "      <td>0.728430</td>\n",
                     "      <td>0.775019</td>\n",
                     "      <td>0.751003</td>\n",
                     "      <td>0.901745</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>30</td>\n",
                     "      <td>0.007700</td>\n",
                     "      <td>0.233239</td>\n",
                     "      <td>0.712500</td>\n",
                     "      <td>0.772009</td>\n",
                     "      <td>0.741062</td>\n",
                     "      <td>0.899336</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>31</td>\n",
                     "      <td>0.007700</td>\n",
                     "      <td>0.231970</td>\n",
                     "      <td>0.730148</td>\n",
                     "      <td>0.781791</td>\n",
                     "      <td>0.755087</td>\n",
                     "      <td>0.905391</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>32</td>\n",
                     "      <td>0.006800</td>\n",
                     "      <td>0.221926</td>\n",
                     "      <td>0.718508</td>\n",
                     "      <td>0.768247</td>\n",
                     "      <td>0.742545</td>\n",
                     "      <td>0.900638</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>33</td>\n",
                     "      <td>0.006800</td>\n",
                     "      <td>0.221389</td>\n",
                     "      <td>0.687322</td>\n",
                     "      <td>0.726110</td>\n",
                     "      <td>0.706184</td>\n",
                     "      <td>0.888267</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>34</td>\n",
                     "      <td>0.006800</td>\n",
                     "      <td>0.230451</td>\n",
                     "      <td>0.721358</td>\n",
                     "      <td>0.767494</td>\n",
                     "      <td>0.743711</td>\n",
                     "      <td>0.899466</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>35</td>\n",
                     "      <td>0.006100</td>\n",
                     "      <td>0.237067</td>\n",
                     "      <td>0.725476</td>\n",
                     "      <td>0.773514</td>\n",
                     "      <td>0.748725</td>\n",
                     "      <td>0.903698</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>36</td>\n",
                     "      <td>0.006100</td>\n",
                     "      <td>0.236166</td>\n",
                     "      <td>0.722495</td>\n",
                     "      <td>0.775771</td>\n",
                     "      <td>0.748186</td>\n",
                     "      <td>0.904024</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>37</td>\n",
                     "      <td>0.005400</td>\n",
                     "      <td>0.238393</td>\n",
                     "      <td>0.727337</td>\n",
                     "      <td>0.778781</td>\n",
                     "      <td>0.752180</td>\n",
                     "      <td>0.904219</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>38</td>\n",
                     "      <td>0.005400</td>\n",
                     "      <td>0.237098</td>\n",
                     "      <td>0.719633</td>\n",
                     "      <td>0.766742</td>\n",
                     "      <td>0.742441</td>\n",
                     "      <td>0.901745</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>39</td>\n",
                     "      <td>0.005400</td>\n",
                     "      <td>0.236988</td>\n",
                     "      <td>0.729445</td>\n",
                     "      <td>0.781038</td>\n",
                     "      <td>0.754360</td>\n",
                     "      <td>0.904415</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>40</td>\n",
                     "      <td>0.005000</td>\n",
                     "      <td>0.236959</td>\n",
                     "      <td>0.732534</td>\n",
                     "      <td>0.781038</td>\n",
                     "      <td>0.756009</td>\n",
                     "      <td>0.905261</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table><p>"
                  ],
                  "text/plain":[
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata":{
                  
               },
               "output_type":"display_data"
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "\n",
                  "\n",
                  "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
                  "\n",
                  "\n"
               ]
            },
            {
               "data":{
                  "text/plain":[
                     "TrainOutput(global_step=7640, training_loss=0.009943935345292716, metrics={'train_runtime': 22236.8352, 'train_samples_per_second': 5.477, 'train_steps_per_second': 0.344, 'total_flos': 2.89730746368e+16, 'train_loss': 0.009943935345292716, 'epoch': 40.0})"
                  ]
               },
               "execution_count":22,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "trainer.set_things(labelids, tokenizer, beamsz)\n",
            "trainer.train()"
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            
         },
         "source":[
            "### learning_rate=2e-4, batch_size=16"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":23,
         "metadata":{
            
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "PyTorch: setting up devices\n",
                  "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
               ]
            }
         ],
         "source":[
            "args = Seq2SeqTrainingArguments(\n",
            "    \"T5-pretrained-labelseq-ner-logitsprocessor-lr2e-4-batch-16\", evaluation_strategy=\"epoch\", save_strategy=\"epoch\",\n",
            "    learning_rate=2e-4, num_train_epochs=40, weight_decay=0.01, predict_with_generate=True,\n",
            "    per_device_train_batch_size=16, seed=7, #     no_cuda=True,\n",
            "    )\n",
            "\n",
            "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
            "trainer = MyTrainer(\n",
            "    model=model, args=args, train_dataset=training_set, eval_dataset=val_set,\n",
            "    data_collator=data_collator, compute_metrics=compute_metrics, tokenizer=tokenizer,\n",
            ")\n",
            "beamsz = 5"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":24,
         "metadata":{
            "scrolled":true
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "/home/nanomineduke/anaconda3/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
                  "  FutureWarning,\n",
                  "***** Running training *****\n",
                  "  Num examples = 3045\n",
                  "  Num Epochs = 40\n",
                  "  Instantaneous batch size per device = 16\n",
                  "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
                  "  Gradient Accumulation steps = 1\n",
                  "  Total optimization steps = 7640\n"
               ]
            },
            {
               "data":{
                  "text/html":[
                     "\n",
                     "    <div>\n",
                     "      \n",
                     "      <progress value='7640' max='7640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                     "      [7640/7640 6:12:00, Epoch 40/40]\n",
                     "    </div>\n",
                     "    <table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     " <tr style=\"text-align: left;\">\n",
                     "      <th>Epoch</th>\n",
                     "      <th>Training Loss</th>\n",
                     "      <th>Validation Loss</th>\n",
                     "      <th>Precision</th>\n",
                     "      <th>Recall</th>\n",
                     "      <th>F1</th>\n",
                     "      <th>Accuracy</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <td>1</td>\n",
                     "      <td>No log</td>\n",
                     "      <td>0.205056</td>\n",
                     "      <td>0.635402</td>\n",
                     "      <td>0.677953</td>\n",
                     "      <td>0.655988</td>\n",
                     "      <td>0.865412</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>2</td>\n",
                     "      <td>No log</td>\n",
                     "      <td>0.164358</td>\n",
                     "      <td>0.666438</td>\n",
                     "      <td>0.732129</td>\n",
                     "      <td>0.697741</td>\n",
                     "      <td>0.879086</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>3</td>\n",
                     "      <td>0.021200</td>\n",
                     "      <td>0.148122</td>\n",
                     "      <td>0.685997</td>\n",
                     "      <td>0.729872</td>\n",
                     "      <td>0.707255</td>\n",
                     "      <td>0.883774</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>4</td>\n",
                     "      <td>0.021200</td>\n",
                     "      <td>0.161662</td>\n",
                     "      <td>0.705841</td>\n",
                     "      <td>0.754703</td>\n",
                     "      <td>0.729455</td>\n",
                     "      <td>0.892239</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>5</td>\n",
                     "      <td>0.021200</td>\n",
                     "      <td>0.161924</td>\n",
                     "      <td>0.690210</td>\n",
                     "      <td>0.742664</td>\n",
                     "      <td>0.715477</td>\n",
                     "      <td>0.892434</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>6</td>\n",
                     "      <td>0.019300</td>\n",
                     "      <td>0.155263</td>\n",
                     "      <td>0.695497</td>\n",
                     "      <td>0.732129</td>\n",
                     "      <td>0.713343</td>\n",
                     "      <td>0.885337</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>7</td>\n",
                     "      <td>0.019300</td>\n",
                     "      <td>0.158418</td>\n",
                     "      <td>0.707143</td>\n",
                     "      <td>0.744921</td>\n",
                     "      <td>0.725540</td>\n",
                     "      <td>0.896080</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>8</td>\n",
                     "      <td>0.018000</td>\n",
                     "      <td>0.157383</td>\n",
                     "      <td>0.695431</td>\n",
                     "      <td>0.721595</td>\n",
                     "      <td>0.708272</td>\n",
                     "      <td>0.888071</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>9</td>\n",
                     "      <td>0.018000</td>\n",
                     "      <td>0.158764</td>\n",
                     "      <td>0.712700</td>\n",
                     "      <td>0.772761</td>\n",
                     "      <td>0.741516</td>\n",
                     "      <td>0.901680</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>10</td>\n",
                     "      <td>0.018000</td>\n",
                     "      <td>0.159907</td>\n",
                     "      <td>0.703678</td>\n",
                     "      <td>0.762980</td>\n",
                     "      <td>0.732130</td>\n",
                     "      <td>0.894908</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>11</td>\n",
                     "      <td>0.015000</td>\n",
                     "      <td>0.169772</td>\n",
                     "      <td>0.688937</td>\n",
                     "      <td>0.721595</td>\n",
                     "      <td>0.704888</td>\n",
                     "      <td>0.887290</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>12</td>\n",
                     "      <td>0.015000</td>\n",
                     "      <td>0.163704</td>\n",
                     "      <td>0.652778</td>\n",
                     "      <td>0.671934</td>\n",
                     "      <td>0.662217</td>\n",
                     "      <td>0.872444</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>13</td>\n",
                     "      <td>0.015000</td>\n",
                     "      <td>0.180106</td>\n",
                     "      <td>0.693878</td>\n",
                     "      <td>0.767494</td>\n",
                     "      <td>0.728832</td>\n",
                     "      <td>0.893345</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>14</td>\n",
                     "      <td>0.013600</td>\n",
                     "      <td>0.179187</td>\n",
                     "      <td>0.698288</td>\n",
                     "      <td>0.736644</td>\n",
                     "      <td>0.716953</td>\n",
                     "      <td>0.896862</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>15</td>\n",
                     "      <td>0.013600</td>\n",
                     "      <td>0.165486</td>\n",
                     "      <td>0.717035</td>\n",
                     "      <td>0.756960</td>\n",
                     "      <td>0.736457</td>\n",
                     "      <td>0.893215</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>16</td>\n",
                     "      <td>0.012400</td>\n",
                     "      <td>0.179939</td>\n",
                     "      <td>0.720670</td>\n",
                     "      <td>0.776524</td>\n",
                     "      <td>0.747555</td>\n",
                     "      <td>0.899466</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>17</td>\n",
                     "      <td>0.012400</td>\n",
                     "      <td>0.190218</td>\n",
                     "      <td>0.715475</td>\n",
                     "      <td>0.775771</td>\n",
                     "      <td>0.744404</td>\n",
                     "      <td>0.896796</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>18</td>\n",
                     "      <td>0.012400</td>\n",
                     "      <td>0.181272</td>\n",
                     "      <td>0.708392</td>\n",
                     "      <td>0.762227</td>\n",
                     "      <td>0.734324</td>\n",
                     "      <td>0.900899</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>19</td>\n",
                     "      <td>0.011200</td>\n",
                     "      <td>0.182377</td>\n",
                     "      <td>0.693662</td>\n",
                     "      <td>0.741159</td>\n",
                     "      <td>0.716624</td>\n",
                     "      <td>0.893932</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>20</td>\n",
                     "      <td>0.011200</td>\n",
                     "      <td>0.184076</td>\n",
                     "      <td>0.711911</td>\n",
                     "      <td>0.773514</td>\n",
                     "      <td>0.741435</td>\n",
                     "      <td>0.895950</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>21</td>\n",
                     "      <td>0.009900</td>\n",
                     "      <td>0.198051</td>\n",
                     "      <td>0.715068</td>\n",
                     "      <td>0.785553</td>\n",
                     "      <td>0.748655</td>\n",
                     "      <td>0.900833</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>22</td>\n",
                     "      <td>0.009900</td>\n",
                     "      <td>0.189075</td>\n",
                     "      <td>0.706048</td>\n",
                     "      <td>0.755455</td>\n",
                     "      <td>0.729916</td>\n",
                     "      <td>0.898945</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>23</td>\n",
                     "      <td>0.009900</td>\n",
                     "      <td>0.191871</td>\n",
                     "      <td>0.702914</td>\n",
                     "      <td>0.744169</td>\n",
                     "      <td>0.722953</td>\n",
                     "      <td>0.895038</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>24</td>\n",
                     "      <td>0.009100</td>\n",
                     "      <td>0.187298</td>\n",
                     "      <td>0.720423</td>\n",
                     "      <td>0.769752</td>\n",
                     "      <td>0.744271</td>\n",
                     "      <td>0.903373</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>25</td>\n",
                     "      <td>0.009100</td>\n",
                     "      <td>0.201479</td>\n",
                     "      <td>0.721914</td>\n",
                     "      <td>0.783296</td>\n",
                     "      <td>0.751353</td>\n",
                     "      <td>0.907735</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>26</td>\n",
                     "      <td>0.009100</td>\n",
                     "      <td>0.202278</td>\n",
                     "      <td>0.723152</td>\n",
                     "      <td>0.780286</td>\n",
                     "      <td>0.750633</td>\n",
                     "      <td>0.909233</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>27</td>\n",
                     "      <td>0.008400</td>\n",
                     "      <td>0.216566</td>\n",
                     "      <td>0.733473</td>\n",
                     "      <td>0.793078</td>\n",
                     "      <td>0.762111</td>\n",
                     "      <td>0.909233</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>28</td>\n",
                     "      <td>0.008400</td>\n",
                     "      <td>0.192785</td>\n",
                     "      <td>0.745545</td>\n",
                     "      <td>0.787058</td>\n",
                     "      <td>0.765739</td>\n",
                     "      <td>0.911837</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>29</td>\n",
                     "      <td>0.007100</td>\n",
                     "      <td>0.201556</td>\n",
                     "      <td>0.753901</td>\n",
                     "      <td>0.799850</td>\n",
                     "      <td>0.776196</td>\n",
                     "      <td>0.915288</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>30</td>\n",
                     "      <td>0.007100</td>\n",
                     "      <td>0.218339</td>\n",
                     "      <td>0.732819</td>\n",
                     "      <td>0.786305</td>\n",
                     "      <td>0.758621</td>\n",
                     "      <td>0.909298</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>31</td>\n",
                     "      <td>0.007100</td>\n",
                     "      <td>0.198504</td>\n",
                     "      <td>0.760823</td>\n",
                     "      <td>0.806622</td>\n",
                     "      <td>0.783053</td>\n",
                     "      <td>0.917177</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>32</td>\n",
                     "      <td>0.006600</td>\n",
                     "      <td>0.212019</td>\n",
                     "      <td>0.747716</td>\n",
                     "      <td>0.800602</td>\n",
                     "      <td>0.773256</td>\n",
                     "      <td>0.913205</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>33</td>\n",
                     "      <td>0.006600</td>\n",
                     "      <td>0.224493</td>\n",
                     "      <td>0.727594</td>\n",
                     "      <td>0.775771</td>\n",
                     "      <td>0.750910</td>\n",
                     "      <td>0.906042</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>34</td>\n",
                     "      <td>0.006600</td>\n",
                     "      <td>0.217143</td>\n",
                     "      <td>0.734965</td>\n",
                     "      <td>0.790820</td>\n",
                     "      <td>0.761870</td>\n",
                     "      <td>0.911121</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>35</td>\n",
                     "      <td>0.005500</td>\n",
                     "      <td>0.220520</td>\n",
                     "      <td>0.738827</td>\n",
                     "      <td>0.796087</td>\n",
                     "      <td>0.766389</td>\n",
                     "      <td>0.912619</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>36</td>\n",
                     "      <td>0.005500</td>\n",
                     "      <td>0.219554</td>\n",
                     "      <td>0.733426</td>\n",
                     "      <td>0.790820</td>\n",
                     "      <td>0.761043</td>\n",
                     "      <td>0.910145</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>37</td>\n",
                     "      <td>0.004800</td>\n",
                     "      <td>0.227571</td>\n",
                     "      <td>0.739620</td>\n",
                     "      <td>0.790820</td>\n",
                     "      <td>0.764364</td>\n",
                     "      <td>0.910340</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>38</td>\n",
                     "      <td>0.004800</td>\n",
                     "      <td>0.225453</td>\n",
                     "      <td>0.731828</td>\n",
                     "      <td>0.780286</td>\n",
                     "      <td>0.755280</td>\n",
                     "      <td>0.906759</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>39</td>\n",
                     "      <td>0.004800</td>\n",
                     "      <td>0.224919</td>\n",
                     "      <td>0.743808</td>\n",
                     "      <td>0.790820</td>\n",
                     "      <td>0.766594</td>\n",
                     "      <td>0.910340</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>40</td>\n",
                     "      <td>0.004200</td>\n",
                     "      <td>0.224355</td>\n",
                     "      <td>0.737994</td>\n",
                     "      <td>0.786305</td>\n",
                     "      <td>0.761384</td>\n",
                     "      <td>0.909363</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table><p>"
                  ],
                  "text/plain":[
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata":{
                  
               },
               "output_type":"display_data"
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "\n",
                  "\n",
                  "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
                  "\n",
                  "\n"
               ]
            },
            {
               "data":{
                  "text/plain":[
                     "TrainOutput(global_step=7640, training_loss=0.0109601586823064, metrics={'train_runtime': 22321.3553, 'train_samples_per_second': 5.457, 'train_steps_per_second': 0.342, 'total_flos': 2.89730746368e+16, 'train_loss': 0.0109601586823064, 'epoch': 40.0})"
                  ]
               },
               "execution_count":24,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "trainer.set_things(labelids, tokenizer, beamsz)\n",
            "trainer.train()"
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            
         },
         "source":[
            "### learning_rate=3e-4, batch_size=16, weight_decay=1e-2"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":25,
         "metadata":{
            "scrolled":true
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "PyTorch: setting up devices\n",
                  "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
               ]
            }
         ],
         "source":[
            "args = Seq2SeqTrainingArguments(\n",
            "    \"T5-pretrained-labelseq-ner-logitsprocessor-lr3e-4-batch-16\", evaluation_strategy=\"epoch\", save_strategy=\"epoch\",\n",
            "    learning_rate=3e-4, num_train_epochs=40, weight_decay=0.01, predict_with_generate=True,\n",
            "    per_device_train_batch_size=16, seed=7, #     no_cuda=True,\n",
            "    )\n",
            "\n",
            "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
            "trainer = MyTrainer(\n",
            "    model=model, args=args, train_dataset=training_set, eval_dataset=val_set,\n",
            "    data_collator=data_collator, compute_metrics=compute_metrics, tokenizer=tokenizer,\n",
            ")\n",
            "beamsz = 5"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":26,
         "metadata":{
            "scrolled":true
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "/home/nanomineduke/anaconda3/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
                  "  FutureWarning,\n",
                  "***** Running training *****\n",
                  "  Num examples = 3045\n",
                  "  Num Epochs = 40\n",
                  "  Instantaneous batch size per device = 16\n",
                  "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
                  "  Gradient Accumulation steps = 1\n",
                  "  Total optimization steps = 7640\n"
               ]
            },
            {
               "data":{
                  "text/html":[
                     "\n",
                     "    <div>\n",
                     "      \n",
                     "      <progress value='7640' max='7640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                     "      [7640/7640 6:07:12, Epoch 40/40]\n",
                     "    </div>\n",
                     "    <table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     " <tr style=\"text-align: left;\">\n",
                     "      <th>Epoch</th>\n",
                     "      <th>Training Loss</th>\n",
                     "      <th>Validation Loss</th>\n",
                     "      <th>Precision</th>\n",
                     "      <th>Recall</th>\n",
                     "      <th>F1</th>\n",
                     "      <th>Accuracy</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <td>1</td>\n",
                     "      <td>No log</td>\n",
                     "      <td>0.168720</td>\n",
                     "      <td>0.699489</td>\n",
                     "      <td>0.721595</td>\n",
                     "      <td>0.710370</td>\n",
                     "      <td>0.879867</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>2</td>\n",
                     "      <td>No log</td>\n",
                     "      <td>0.140741</td>\n",
                     "      <td>0.730030</td>\n",
                     "      <td>0.742664</td>\n",
                     "      <td>0.736292</td>\n",
                     "      <td>0.894452</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>3</td>\n",
                     "      <td>0.025600</td>\n",
                     "      <td>0.155511</td>\n",
                     "      <td>0.705202</td>\n",
                     "      <td>0.734387</td>\n",
                     "      <td>0.719499</td>\n",
                     "      <td>0.884881</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>4</td>\n",
                     "      <td>0.025600</td>\n",
                     "      <td>0.139898</td>\n",
                     "      <td>0.718412</td>\n",
                     "      <td>0.748683</td>\n",
                     "      <td>0.733235</td>\n",
                     "      <td>0.896601</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>5</td>\n",
                     "      <td>0.025600</td>\n",
                     "      <td>0.164250</td>\n",
                     "      <td>0.719348</td>\n",
                     "      <td>0.763732</td>\n",
                     "      <td>0.740876</td>\n",
                     "      <td>0.898489</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>6</td>\n",
                     "      <td>0.020900</td>\n",
                     "      <td>0.159383</td>\n",
                     "      <td>0.727532</td>\n",
                     "      <td>0.767494</td>\n",
                     "      <td>0.746979</td>\n",
                     "      <td>0.899401</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>7</td>\n",
                     "      <td>0.020900</td>\n",
                     "      <td>0.148544</td>\n",
                     "      <td>0.695622</td>\n",
                     "      <td>0.753198</td>\n",
                     "      <td>0.723266</td>\n",
                     "      <td>0.886639</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>8</td>\n",
                     "      <td>0.019200</td>\n",
                     "      <td>0.147332</td>\n",
                     "      <td>0.726826</td>\n",
                     "      <td>0.778781</td>\n",
                     "      <td>0.751907</td>\n",
                     "      <td>0.894713</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>9</td>\n",
                     "      <td>0.019200</td>\n",
                     "      <td>0.142774</td>\n",
                     "      <td>0.719573</td>\n",
                     "      <td>0.760722</td>\n",
                     "      <td>0.739576</td>\n",
                     "      <td>0.897838</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>10</td>\n",
                     "      <td>0.019200</td>\n",
                     "      <td>0.190971</td>\n",
                     "      <td>0.705314</td>\n",
                     "      <td>0.768999</td>\n",
                     "      <td>0.735781</td>\n",
                     "      <td>0.887811</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>11</td>\n",
                     "      <td>0.017100</td>\n",
                     "      <td>0.149061</td>\n",
                     "      <td>0.733238</td>\n",
                     "      <td>0.773514</td>\n",
                     "      <td>0.752838</td>\n",
                     "      <td>0.898424</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>12</td>\n",
                     "      <td>0.017100</td>\n",
                     "      <td>0.159901</td>\n",
                     "      <td>0.719599</td>\n",
                     "      <td>0.756960</td>\n",
                     "      <td>0.737807</td>\n",
                     "      <td>0.890871</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>13</td>\n",
                     "      <td>0.017100</td>\n",
                     "      <td>0.166535</td>\n",
                     "      <td>0.696751</td>\n",
                     "      <td>0.726110</td>\n",
                     "      <td>0.711127</td>\n",
                     "      <td>0.891913</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>14</td>\n",
                     "      <td>0.014800</td>\n",
                     "      <td>0.185761</td>\n",
                     "      <td>0.727336</td>\n",
                     "      <td>0.790820</td>\n",
                     "      <td>0.757751</td>\n",
                     "      <td>0.900768</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>15</td>\n",
                     "      <td>0.014800</td>\n",
                     "      <td>0.174553</td>\n",
                     "      <td>0.721121</td>\n",
                     "      <td>0.793830</td>\n",
                     "      <td>0.755731</td>\n",
                     "      <td>0.903568</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>16</td>\n",
                     "      <td>0.013500</td>\n",
                     "      <td>0.160440</td>\n",
                     "      <td>0.734088</td>\n",
                     "      <td>0.781038</td>\n",
                     "      <td>0.756836</td>\n",
                     "      <td>0.904089</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>17</td>\n",
                     "      <td>0.013500</td>\n",
                     "      <td>0.158938</td>\n",
                     "      <td>0.743119</td>\n",
                     "      <td>0.792325</td>\n",
                     "      <td>0.766934</td>\n",
                     "      <td>0.907084</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>18</td>\n",
                     "      <td>0.013500</td>\n",
                     "      <td>0.156267</td>\n",
                     "      <td>0.715782</td>\n",
                     "      <td>0.771257</td>\n",
                     "      <td>0.742485</td>\n",
                     "      <td>0.900117</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>19</td>\n",
                     "      <td>0.012100</td>\n",
                     "      <td>0.158481</td>\n",
                     "      <td>0.741329</td>\n",
                     "      <td>0.772009</td>\n",
                     "      <td>0.756358</td>\n",
                     "      <td>0.900443</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>20</td>\n",
                     "      <td>0.012100</td>\n",
                     "      <td>0.141095</td>\n",
                     "      <td>0.760933</td>\n",
                     "      <td>0.785553</td>\n",
                     "      <td>0.773047</td>\n",
                     "      <td>0.906628</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>21</td>\n",
                     "      <td>0.011600</td>\n",
                     "      <td>0.160535</td>\n",
                     "      <td>0.747126</td>\n",
                     "      <td>0.782543</td>\n",
                     "      <td>0.764425</td>\n",
                     "      <td>0.907280</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>22</td>\n",
                     "      <td>0.011600</td>\n",
                     "      <td>0.156425</td>\n",
                     "      <td>0.747308</td>\n",
                     "      <td>0.783296</td>\n",
                     "      <td>0.764879</td>\n",
                     "      <td>0.906759</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>23</td>\n",
                     "      <td>0.011600</td>\n",
                     "      <td>0.159784</td>\n",
                     "      <td>0.758304</td>\n",
                     "      <td>0.807374</td>\n",
                     "      <td>0.782070</td>\n",
                     "      <td>0.911642</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>24</td>\n",
                     "      <td>0.009500</td>\n",
                     "      <td>0.166775</td>\n",
                     "      <td>0.771511</td>\n",
                     "      <td>0.802859</td>\n",
                     "      <td>0.786873</td>\n",
                     "      <td>0.911447</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>25</td>\n",
                     "      <td>0.009500</td>\n",
                     "      <td>0.177737</td>\n",
                     "      <td>0.767223</td>\n",
                     "      <td>0.796087</td>\n",
                     "      <td>0.781388</td>\n",
                     "      <td>0.909428</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>26</td>\n",
                     "      <td>0.009500</td>\n",
                     "      <td>0.185975</td>\n",
                     "      <td>0.735465</td>\n",
                     "      <td>0.761475</td>\n",
                     "      <td>0.748244</td>\n",
                     "      <td>0.902526</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>27</td>\n",
                     "      <td>0.007900</td>\n",
                     "      <td>0.174699</td>\n",
                     "      <td>0.758646</td>\n",
                     "      <td>0.792325</td>\n",
                     "      <td>0.775120</td>\n",
                     "      <td>0.911056</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>28</td>\n",
                     "      <td>0.007900</td>\n",
                     "      <td>0.187372</td>\n",
                     "      <td>0.775148</td>\n",
                     "      <td>0.788563</td>\n",
                     "      <td>0.781798</td>\n",
                     "      <td>0.911968</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>29</td>\n",
                     "      <td>0.007100</td>\n",
                     "      <td>0.197790</td>\n",
                     "      <td>0.744862</td>\n",
                     "      <td>0.790820</td>\n",
                     "      <td>0.767153</td>\n",
                     "      <td>0.908191</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>30</td>\n",
                     "      <td>0.007100</td>\n",
                     "      <td>0.196150</td>\n",
                     "      <td>0.758845</td>\n",
                     "      <td>0.790820</td>\n",
                     "      <td>0.774503</td>\n",
                     "      <td>0.908842</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>31</td>\n",
                     "      <td>0.007100</td>\n",
                     "      <td>0.183052</td>\n",
                     "      <td>0.775749</td>\n",
                     "      <td>0.799097</td>\n",
                     "      <td>0.787250</td>\n",
                     "      <td>0.917112</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>32</td>\n",
                     "      <td>0.006600</td>\n",
                     "      <td>0.189239</td>\n",
                     "      <td>0.768512</td>\n",
                     "      <td>0.804364</td>\n",
                     "      <td>0.786029</td>\n",
                     "      <td>0.913465</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>33</td>\n",
                     "      <td>0.006600</td>\n",
                     "      <td>0.200584</td>\n",
                     "      <td>0.770065</td>\n",
                     "      <td>0.801354</td>\n",
                     "      <td>0.785398</td>\n",
                     "      <td>0.913856</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>34</td>\n",
                     "      <td>0.006600</td>\n",
                     "      <td>0.206930</td>\n",
                     "      <td>0.772727</td>\n",
                     "      <td>0.805869</td>\n",
                     "      <td>0.788950</td>\n",
                     "      <td>0.915093</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>35</td>\n",
                     "      <td>0.004900</td>\n",
                     "      <td>0.220965</td>\n",
                     "      <td>0.758547</td>\n",
                     "      <td>0.801354</td>\n",
                     "      <td>0.779363</td>\n",
                     "      <td>0.910340</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>36</td>\n",
                     "      <td>0.004900</td>\n",
                     "      <td>0.211453</td>\n",
                     "      <td>0.764368</td>\n",
                     "      <td>0.800602</td>\n",
                     "      <td>0.782065</td>\n",
                     "      <td>0.910275</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>37</td>\n",
                     "      <td>0.004200</td>\n",
                     "      <td>0.221509</td>\n",
                     "      <td>0.766739</td>\n",
                     "      <td>0.801354</td>\n",
                     "      <td>0.783664</td>\n",
                     "      <td>0.910926</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>38</td>\n",
                     "      <td>0.004200</td>\n",
                     "      <td>0.228762</td>\n",
                     "      <td>0.753901</td>\n",
                     "      <td>0.799850</td>\n",
                     "      <td>0.776196</td>\n",
                     "      <td>0.907540</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>39</td>\n",
                     "      <td>0.004200</td>\n",
                     "      <td>0.230212</td>\n",
                     "      <td>0.760230</td>\n",
                     "      <td>0.796840</td>\n",
                     "      <td>0.778104</td>\n",
                     "      <td>0.908321</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>40</td>\n",
                     "      <td>0.003400</td>\n",
                     "      <td>0.230778</td>\n",
                     "      <td>0.756602</td>\n",
                     "      <td>0.797592</td>\n",
                     "      <td>0.776557</td>\n",
                     "      <td>0.908517</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table><p>"
                  ],
                  "text/plain":[
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata":{
                  
               },
               "output_type":"display_data"
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "\n",
                  "\n",
                  "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
                  "\n",
                  "\n"
               ]
            },
            {
               "data":{
                  "text/plain":[
                     "TrainOutput(global_step=7640, training_loss=0.011748976190208765, metrics={'train_runtime': 22033.7458, 'train_samples_per_second': 5.528, 'train_steps_per_second': 0.347, 'total_flos': 2.89730746368e+16, 'train_loss': 0.011748976190208765, 'epoch': 40.0})"
                  ]
               },
               "execution_count":26,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "trainer.set_things(labelids, tokenizer, beamsz)\n",
            "trainer.train()"
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            
         },
         "source":[
            "### learning_rate=3e-4, batch_size=16,weight_decay=1e-1"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":27,
         "metadata":{
            "scrolled":true
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "PyTorch: setting up devices\n",
                  "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
               ]
            }
         ],
         "source":[
            "args = Seq2SeqTrainingArguments(\n",
            "    \"T5-pretrained-labelseq-ner-logitsprocessor-lr3e-4-batch-16-wd-1e-1\", evaluation_strategy=\"epoch\", save_strategy=\"epoch\",\n",
            "    learning_rate=3e-4, num_train_epochs=40, weight_decay=0.1, predict_with_generate=True,\n",
            "    per_device_train_batch_size=16, seed=7, #     no_cuda=True,\n",
            "    )\n",
            "\n",
            "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
            "trainer = MyTrainer(\n",
            "    model=model, args=args, train_dataset=training_set, eval_dataset=val_set,\n",
            "    data_collator=data_collator, compute_metrics=compute_metrics, tokenizer=tokenizer,\n",
            ")\n",
            "beamsz = 5"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":28,
         "metadata":{
            
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "/home/nanomineduke/anaconda3/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
                  "  FutureWarning,\n",
                  "***** Running training *****\n",
                  "  Num examples = 3045\n",
                  "  Num Epochs = 40\n",
                  "  Instantaneous batch size per device = 16\n",
                  "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
                  "  Gradient Accumulation steps = 1\n",
                  "  Total optimization steps = 7640\n"
               ]
            },
            {
               "data":{
                  "text/html":[
                     "\n",
                     "    <div>\n",
                     "      \n",
                     "      <progress value='7640' max='7640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                     "      [7640/7640 6:08:53, Epoch 40/40]\n",
                     "    </div>\n",
                     "    <table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     " <tr style=\"text-align: left;\">\n",
                     "      <th>Epoch</th>\n",
                     "      <th>Training Loss</th>\n",
                     "      <th>Validation Loss</th>\n",
                     "      <th>Precision</th>\n",
                     "      <th>Recall</th>\n",
                     "      <th>F1</th>\n",
                     "      <th>Accuracy</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <td>1</td>\n",
                     "      <td>No log</td>\n",
                     "      <td>0.167076</td>\n",
                     "      <td>0.719573</td>\n",
                     "      <td>0.760722</td>\n",
                     "      <td>0.739576</td>\n",
                     "      <td>0.901354</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>2</td>\n",
                     "      <td>No log</td>\n",
                     "      <td>0.174013</td>\n",
                     "      <td>0.698571</td>\n",
                     "      <td>0.735892</td>\n",
                     "      <td>0.716746</td>\n",
                     "      <td>0.888657</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>3</td>\n",
                     "      <td>0.019700</td>\n",
                     "      <td>0.128384</td>\n",
                     "      <td>0.737670</td>\n",
                     "      <td>0.776524</td>\n",
                     "      <td>0.756598</td>\n",
                     "      <td>0.899857</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>4</td>\n",
                     "      <td>0.019700</td>\n",
                     "      <td>0.148579</td>\n",
                     "      <td>0.708897</td>\n",
                     "      <td>0.749436</td>\n",
                     "      <td>0.728603</td>\n",
                     "      <td>0.897122</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>5</td>\n",
                     "      <td>0.019700</td>\n",
                     "      <td>0.179034</td>\n",
                     "      <td>0.677669</td>\n",
                     "      <td>0.726110</td>\n",
                     "      <td>0.701053</td>\n",
                     "      <td>0.886574</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>6</td>\n",
                     "      <td>0.016100</td>\n",
                     "      <td>0.165121</td>\n",
                     "      <td>0.734150</td>\n",
                     "      <td>0.766742</td>\n",
                     "      <td>0.750092</td>\n",
                     "      <td>0.899401</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>7</td>\n",
                     "      <td>0.016100</td>\n",
                     "      <td>0.171342</td>\n",
                     "      <td>0.725783</td>\n",
                     "      <td>0.766742</td>\n",
                     "      <td>0.745701</td>\n",
                     "      <td>0.898620</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>8</td>\n",
                     "      <td>0.016500</td>\n",
                     "      <td>0.159724</td>\n",
                     "      <td>0.673759</td>\n",
                     "      <td>0.714823</td>\n",
                     "      <td>0.693684</td>\n",
                     "      <td>0.879997</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>9</td>\n",
                     "      <td>0.016500</td>\n",
                     "      <td>0.198320</td>\n",
                     "      <td>0.709655</td>\n",
                     "      <td>0.774266</td>\n",
                     "      <td>0.740554</td>\n",
                     "      <td>0.896731</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>10</td>\n",
                     "      <td>0.016500</td>\n",
                     "      <td>0.174795</td>\n",
                     "      <td>0.708799</td>\n",
                     "      <td>0.763732</td>\n",
                     "      <td>0.735241</td>\n",
                     "      <td>0.894973</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>11</td>\n",
                     "      <td>0.013400</td>\n",
                     "      <td>0.141477</td>\n",
                     "      <td>0.723810</td>\n",
                     "      <td>0.743416</td>\n",
                     "      <td>0.733482</td>\n",
                     "      <td>0.894583</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>12</td>\n",
                     "      <td>0.013400</td>\n",
                     "      <td>0.154147</td>\n",
                     "      <td>0.703069</td>\n",
                     "      <td>0.741159</td>\n",
                     "      <td>0.721612</td>\n",
                     "      <td>0.892499</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>13</td>\n",
                     "      <td>0.013400</td>\n",
                     "      <td>0.163634</td>\n",
                     "      <td>0.716714</td>\n",
                     "      <td>0.761475</td>\n",
                     "      <td>0.738417</td>\n",
                     "      <td>0.897513</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>14</td>\n",
                     "      <td>0.012700</td>\n",
                     "      <td>0.158375</td>\n",
                     "      <td>0.740529</td>\n",
                     "      <td>0.779533</td>\n",
                     "      <td>0.759531</td>\n",
                     "      <td>0.901289</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>15</td>\n",
                     "      <td>0.012700</td>\n",
                     "      <td>0.167508</td>\n",
                     "      <td>0.742595</td>\n",
                     "      <td>0.792325</td>\n",
                     "      <td>0.766655</td>\n",
                     "      <td>0.903959</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>16</td>\n",
                     "      <td>0.010700</td>\n",
                     "      <td>0.162186</td>\n",
                     "      <td>0.754487</td>\n",
                     "      <td>0.790820</td>\n",
                     "      <td>0.772226</td>\n",
                     "      <td>0.906303</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>17</td>\n",
                     "      <td>0.010700</td>\n",
                     "      <td>0.167946</td>\n",
                     "      <td>0.736140</td>\n",
                     "      <td>0.789315</td>\n",
                     "      <td>0.761801</td>\n",
                     "      <td>0.906954</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>18</td>\n",
                     "      <td>0.010700</td>\n",
                     "      <td>0.175400</td>\n",
                     "      <td>0.755443</td>\n",
                     "      <td>0.783296</td>\n",
                     "      <td>0.769117</td>\n",
                     "      <td>0.906824</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>19</td>\n",
                     "      <td>0.009100</td>\n",
                     "      <td>0.166382</td>\n",
                     "      <td>0.717615</td>\n",
                     "      <td>0.787810</td>\n",
                     "      <td>0.751076</td>\n",
                     "      <td>0.899987</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>20</td>\n",
                     "      <td>0.009100</td>\n",
                     "      <td>0.164270</td>\n",
                     "      <td>0.743080</td>\n",
                     "      <td>0.787810</td>\n",
                     "      <td>0.764792</td>\n",
                     "      <td>0.906889</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>21</td>\n",
                     "      <td>0.009000</td>\n",
                     "      <td>0.187164</td>\n",
                     "      <td>0.748575</td>\n",
                     "      <td>0.790820</td>\n",
                     "      <td>0.769118</td>\n",
                     "      <td>0.908517</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>22</td>\n",
                     "      <td>0.009000</td>\n",
                     "      <td>0.170089</td>\n",
                     "      <td>0.744203</td>\n",
                     "      <td>0.772761</td>\n",
                     "      <td>0.758213</td>\n",
                     "      <td>0.903503</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>23</td>\n",
                     "      <td>0.009000</td>\n",
                     "      <td>0.173651</td>\n",
                     "      <td>0.768613</td>\n",
                     "      <td>0.792325</td>\n",
                     "      <td>0.780289</td>\n",
                     "      <td>0.911642</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>24</td>\n",
                     "      <td>0.008100</td>\n",
                     "      <td>0.182631</td>\n",
                     "      <td>0.751949</td>\n",
                     "      <td>0.798345</td>\n",
                     "      <td>0.774453</td>\n",
                     "      <td>0.904610</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>25</td>\n",
                     "      <td>0.008100</td>\n",
                     "      <td>0.206767</td>\n",
                     "      <td>0.760776</td>\n",
                     "      <td>0.796840</td>\n",
                     "      <td>0.778390</td>\n",
                     "      <td>0.910210</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>26</td>\n",
                     "      <td>0.008100</td>\n",
                     "      <td>0.192507</td>\n",
                     "      <td>0.753561</td>\n",
                     "      <td>0.796087</td>\n",
                     "      <td>0.774241</td>\n",
                     "      <td>0.913140</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>27</td>\n",
                     "      <td>0.006900</td>\n",
                     "      <td>0.206944</td>\n",
                     "      <td>0.760634</td>\n",
                     "      <td>0.793830</td>\n",
                     "      <td>0.776878</td>\n",
                     "      <td>0.914312</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>28</td>\n",
                     "      <td>0.006900</td>\n",
                     "      <td>0.190779</td>\n",
                     "      <td>0.757163</td>\n",
                     "      <td>0.795335</td>\n",
                     "      <td>0.775780</td>\n",
                     "      <td>0.913726</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>29</td>\n",
                     "      <td>0.006200</td>\n",
                     "      <td>0.196483</td>\n",
                     "      <td>0.758447</td>\n",
                     "      <td>0.793830</td>\n",
                     "      <td>0.775735</td>\n",
                     "      <td>0.910079</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>30</td>\n",
                     "      <td>0.006200</td>\n",
                     "      <td>0.199029</td>\n",
                     "      <td>0.763518</td>\n",
                     "      <td>0.796840</td>\n",
                     "      <td>0.779823</td>\n",
                     "      <td>0.910861</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>31</td>\n",
                     "      <td>0.006200</td>\n",
                     "      <td>0.203603</td>\n",
                     "      <td>0.760776</td>\n",
                     "      <td>0.796840</td>\n",
                     "      <td>0.778390</td>\n",
                     "      <td>0.910145</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>32</td>\n",
                     "      <td>0.004900</td>\n",
                     "      <td>0.215319</td>\n",
                     "      <td>0.762143</td>\n",
                     "      <td>0.802859</td>\n",
                     "      <td>0.781971</td>\n",
                     "      <td>0.912554</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>33</td>\n",
                     "      <td>0.004900</td>\n",
                     "      <td>0.221958</td>\n",
                     "      <td>0.756776</td>\n",
                     "      <td>0.798345</td>\n",
                     "      <td>0.777005</td>\n",
                     "      <td>0.910145</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>34</td>\n",
                     "      <td>0.004900</td>\n",
                     "      <td>0.220239</td>\n",
                     "      <td>0.768732</td>\n",
                     "      <td>0.802859</td>\n",
                     "      <td>0.785425</td>\n",
                     "      <td>0.915744</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>35</td>\n",
                     "      <td>0.004000</td>\n",
                     "      <td>0.233034</td>\n",
                     "      <td>0.768023</td>\n",
                     "      <td>0.809631</td>\n",
                     "      <td>0.788278</td>\n",
                     "      <td>0.914051</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>36</td>\n",
                     "      <td>0.004000</td>\n",
                     "      <td>0.236771</td>\n",
                     "      <td>0.753705</td>\n",
                     "      <td>0.803612</td>\n",
                     "      <td>0.777859</td>\n",
                     "      <td>0.906694</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>37</td>\n",
                     "      <td>0.003100</td>\n",
                     "      <td>0.233176</td>\n",
                     "      <td>0.774910</td>\n",
                     "      <td>0.813394</td>\n",
                     "      <td>0.793686</td>\n",
                     "      <td>0.915614</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>38</td>\n",
                     "      <td>0.003100</td>\n",
                     "      <td>0.241092</td>\n",
                     "      <td>0.766595</td>\n",
                     "      <td>0.808126</td>\n",
                     "      <td>0.786813</td>\n",
                     "      <td>0.911968</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>39</td>\n",
                     "      <td>0.003100</td>\n",
                     "      <td>0.238565</td>\n",
                     "      <td>0.765882</td>\n",
                     "      <td>0.807374</td>\n",
                     "      <td>0.786081</td>\n",
                     "      <td>0.913335</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>40</td>\n",
                     "      <td>0.002800</td>\n",
                     "      <td>0.237741</td>\n",
                     "      <td>0.767908</td>\n",
                     "      <td>0.806622</td>\n",
                     "      <td>0.786789</td>\n",
                     "      <td>0.912944</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table><p>"
                  ],
                  "text/plain":[
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata":{
                  
               },
               "output_type":"display_data"
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "\n",
                  "\n",
                  "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
                  "\n",
                  "\n"
               ]
            },
            {
               "data":{
                  "text/plain":[
                     "TrainOutput(global_step=7640, training_loss=0.009427958137857977, metrics={'train_runtime': 22135.1556, 'train_samples_per_second': 5.503, 'train_steps_per_second': 0.345, 'total_flos': 2.89730746368e+16, 'train_loss': 0.009427958137857977, 'epoch': 40.0})"
                  ]
               },
               "execution_count":28,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "trainer.set_things(labelids, tokenizer, beamsz)\n",
            "trainer.train()"
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            
         },
         "source":[
            "### learning_rate=3e-4, batch_size=16,weight_decay=1e-3"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":29,
         "metadata":{
            "scrolled":true
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "PyTorch: setting up devices\n",
                  "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
               ]
            }
         ],
         "source":[
            "args = Seq2SeqTrainingArguments(\n",
            "    \"T5-pretrained-labelseq-ner-logitsprocessor-lr3e-4-batch-16-wd-1e-3\", evaluation_strategy=\"epoch\", save_strategy=\"epoch\",\n",
            "    learning_rate=3e-4, num_train_epochs=40, weight_decay=1e-3, predict_with_generate=True,\n",
            "    per_device_train_batch_size=16, seed=7, #     no_cuda=True,\n",
            "    )\n",
            "\n",
            "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
            "trainer = MyTrainer(\n",
            "    model=model, args=args, train_dataset=training_set, eval_dataset=val_set,\n",
            "    data_collator=data_collator, compute_metrics=compute_metrics, tokenizer=tokenizer,\n",
            ")\n",
            "beamsz = 5"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":30,
         "metadata":{
            
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "/home/nanomineduke/anaconda3/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
                  "  FutureWarning,\n",
                  "***** Running training *****\n",
                  "  Num examples = 3045\n",
                  "  Num Epochs = 40\n",
                  "  Instantaneous batch size per device = 16\n",
                  "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
                  "  Gradient Accumulation steps = 1\n",
                  "  Total optimization steps = 7640\n"
               ]
            },
            {
               "data":{
                  "text/html":[
                     "\n",
                     "    <div>\n",
                     "      \n",
                     "      <progress value='7640' max='7640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                     "      [7640/7640 6:10:55, Epoch 40/40]\n",
                     "    </div>\n",
                     "    <table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     " <tr style=\"text-align: left;\">\n",
                     "      <th>Epoch</th>\n",
                     "      <th>Training Loss</th>\n",
                     "      <th>Validation Loss</th>\n",
                     "      <th>Precision</th>\n",
                     "      <th>Recall</th>\n",
                     "      <th>F1</th>\n",
                     "      <th>Accuracy</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <td>1</td>\n",
                     "      <td>No log</td>\n",
                     "      <td>0.154543</td>\n",
                     "      <td>0.742229</td>\n",
                     "      <td>0.736644</td>\n",
                     "      <td>0.739426</td>\n",
                     "      <td>0.889504</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>2</td>\n",
                     "      <td>No log</td>\n",
                     "      <td>0.167995</td>\n",
                     "      <td>0.691983</td>\n",
                     "      <td>0.740406</td>\n",
                     "      <td>0.715376</td>\n",
                     "      <td>0.891522</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>3</td>\n",
                     "      <td>0.017000</td>\n",
                     "      <td>0.185671</td>\n",
                     "      <td>0.675958</td>\n",
                     "      <td>0.729872</td>\n",
                     "      <td>0.701881</td>\n",
                     "      <td>0.885337</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>4</td>\n",
                     "      <td>0.017000</td>\n",
                     "      <td>0.135336</td>\n",
                     "      <td>0.745848</td>\n",
                     "      <td>0.777276</td>\n",
                     "      <td>0.761238</td>\n",
                     "      <td>0.899857</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>5</td>\n",
                     "      <td>0.017000</td>\n",
                     "      <td>0.144473</td>\n",
                     "      <td>0.750000</td>\n",
                     "      <td>0.774266</td>\n",
                     "      <td>0.761940</td>\n",
                     "      <td>0.903373</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>6</td>\n",
                     "      <td>0.014800</td>\n",
                     "      <td>0.159257</td>\n",
                     "      <td>0.724426</td>\n",
                     "      <td>0.783296</td>\n",
                     "      <td>0.752711</td>\n",
                     "      <td>0.901485</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>7</td>\n",
                     "      <td>0.014800</td>\n",
                     "      <td>0.157012</td>\n",
                     "      <td>0.720506</td>\n",
                     "      <td>0.772009</td>\n",
                     "      <td>0.745369</td>\n",
                     "      <td>0.895885</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>8</td>\n",
                     "      <td>0.011900</td>\n",
                     "      <td>0.160331</td>\n",
                     "      <td>0.741269</td>\n",
                     "      <td>0.782543</td>\n",
                     "      <td>0.761347</td>\n",
                     "      <td>0.904675</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>9</td>\n",
                     "      <td>0.011900</td>\n",
                     "      <td>0.156097</td>\n",
                     "      <td>0.746408</td>\n",
                     "      <td>0.781791</td>\n",
                     "      <td>0.763690</td>\n",
                     "      <td>0.905131</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>10</td>\n",
                     "      <td>0.011900</td>\n",
                     "      <td>0.159440</td>\n",
                     "      <td>0.744500</td>\n",
                     "      <td>0.789315</td>\n",
                     "      <td>0.766253</td>\n",
                     "      <td>0.908256</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>11</td>\n",
                     "      <td>0.010900</td>\n",
                     "      <td>0.159118</td>\n",
                     "      <td>0.759475</td>\n",
                     "      <td>0.784048</td>\n",
                     "      <td>0.771566</td>\n",
                     "      <td>0.906563</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>12</td>\n",
                     "      <td>0.010900</td>\n",
                     "      <td>0.159297</td>\n",
                     "      <td>0.754972</td>\n",
                     "      <td>0.799850</td>\n",
                     "      <td>0.776763</td>\n",
                     "      <td>0.910210</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>13</td>\n",
                     "      <td>0.010900</td>\n",
                     "      <td>0.150913</td>\n",
                     "      <td>0.756201</td>\n",
                     "      <td>0.802859</td>\n",
                     "      <td>0.778832</td>\n",
                     "      <td>0.912489</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>14</td>\n",
                     "      <td>0.010700</td>\n",
                     "      <td>0.158899</td>\n",
                     "      <td>0.727524</td>\n",
                     "      <td>0.791573</td>\n",
                     "      <td>0.758198</td>\n",
                     "      <td>0.905782</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>15</td>\n",
                     "      <td>0.010700</td>\n",
                     "      <td>0.157857</td>\n",
                     "      <td>0.747269</td>\n",
                     "      <td>0.772009</td>\n",
                     "      <td>0.759437</td>\n",
                     "      <td>0.903829</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>16</td>\n",
                     "      <td>0.010000</td>\n",
                     "      <td>0.173275</td>\n",
                     "      <td>0.748387</td>\n",
                     "      <td>0.785553</td>\n",
                     "      <td>0.766520</td>\n",
                     "      <td>0.907540</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>17</td>\n",
                     "      <td>0.010000</td>\n",
                     "      <td>0.171958</td>\n",
                     "      <td>0.749122</td>\n",
                     "      <td>0.802107</td>\n",
                     "      <td>0.774709</td>\n",
                     "      <td>0.912423</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>18</td>\n",
                     "      <td>0.010000</td>\n",
                     "      <td>0.187580</td>\n",
                     "      <td>0.740818</td>\n",
                     "      <td>0.804364</td>\n",
                     "      <td>0.771284</td>\n",
                     "      <td>0.909038</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>19</td>\n",
                     "      <td>0.008000</td>\n",
                     "      <td>0.176401</td>\n",
                     "      <td>0.750710</td>\n",
                     "      <td>0.795335</td>\n",
                     "      <td>0.772379</td>\n",
                     "      <td>0.910731</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>20</td>\n",
                     "      <td>0.008000</td>\n",
                     "      <td>0.177765</td>\n",
                     "      <td>0.747167</td>\n",
                     "      <td>0.793830</td>\n",
                     "      <td>0.769792</td>\n",
                     "      <td>0.909103</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>21</td>\n",
                     "      <td>0.007200</td>\n",
                     "      <td>0.183167</td>\n",
                     "      <td>0.735915</td>\n",
                     "      <td>0.786305</td>\n",
                     "      <td>0.760276</td>\n",
                     "      <td>0.905326</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>22</td>\n",
                     "      <td>0.007200</td>\n",
                     "      <td>0.184606</td>\n",
                     "      <td>0.751079</td>\n",
                     "      <td>0.785553</td>\n",
                     "      <td>0.767929</td>\n",
                     "      <td>0.907214</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>23</td>\n",
                     "      <td>0.007200</td>\n",
                     "      <td>0.171879</td>\n",
                     "      <td>0.775036</td>\n",
                     "      <td>0.803612</td>\n",
                     "      <td>0.789065</td>\n",
                     "      <td>0.913856</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>24</td>\n",
                     "      <td>0.006500</td>\n",
                     "      <td>0.185180</td>\n",
                     "      <td>0.778761</td>\n",
                     "      <td>0.794582</td>\n",
                     "      <td>0.786592</td>\n",
                     "      <td>0.913270</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>25</td>\n",
                     "      <td>0.006500</td>\n",
                     "      <td>0.174689</td>\n",
                     "      <td>0.772495</td>\n",
                     "      <td>0.794582</td>\n",
                     "      <td>0.783383</td>\n",
                     "      <td>0.914898</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>26</td>\n",
                     "      <td>0.006500</td>\n",
                     "      <td>0.183279</td>\n",
                     "      <td>0.760604</td>\n",
                     "      <td>0.796087</td>\n",
                     "      <td>0.777941</td>\n",
                     "      <td>0.910665</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>27</td>\n",
                     "      <td>0.005000</td>\n",
                     "      <td>0.184891</td>\n",
                     "      <td>0.761151</td>\n",
                     "      <td>0.796087</td>\n",
                     "      <td>0.778227</td>\n",
                     "      <td>0.910079</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>28</td>\n",
                     "      <td>0.005000</td>\n",
                     "      <td>0.191896</td>\n",
                     "      <td>0.757664</td>\n",
                     "      <td>0.781038</td>\n",
                     "      <td>0.769174</td>\n",
                     "      <td>0.907475</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>29</td>\n",
                     "      <td>0.005000</td>\n",
                     "      <td>0.175113</td>\n",
                     "      <td>0.764409</td>\n",
                     "      <td>0.798345</td>\n",
                     "      <td>0.781008</td>\n",
                     "      <td>0.913791</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>30</td>\n",
                     "      <td>0.005000</td>\n",
                     "      <td>0.174495</td>\n",
                     "      <td>0.762076</td>\n",
                     "      <td>0.795335</td>\n",
                     "      <td>0.778351</td>\n",
                     "      <td>0.913791</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>31</td>\n",
                     "      <td>0.005000</td>\n",
                     "      <td>0.194919</td>\n",
                     "      <td>0.758423</td>\n",
                     "      <td>0.796087</td>\n",
                     "      <td>0.776799</td>\n",
                     "      <td>0.912749</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>32</td>\n",
                     "      <td>0.004100</td>\n",
                     "      <td>0.197319</td>\n",
                     "      <td>0.755508</td>\n",
                     "      <td>0.799850</td>\n",
                     "      <td>0.777047</td>\n",
                     "      <td>0.914702</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>33</td>\n",
                     "      <td>0.004100</td>\n",
                     "      <td>0.197280</td>\n",
                     "      <td>0.766187</td>\n",
                     "      <td>0.801354</td>\n",
                     "      <td>0.783376</td>\n",
                     "      <td>0.915028</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>34</td>\n",
                     "      <td>0.004100</td>\n",
                     "      <td>0.205042</td>\n",
                     "      <td>0.754784</td>\n",
                     "      <td>0.801354</td>\n",
                     "      <td>0.777372</td>\n",
                     "      <td>0.915093</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>35</td>\n",
                     "      <td>0.003500</td>\n",
                     "      <td>0.209010</td>\n",
                     "      <td>0.748580</td>\n",
                     "      <td>0.793078</td>\n",
                     "      <td>0.770186</td>\n",
                     "      <td>0.910861</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>36</td>\n",
                     "      <td>0.003500</td>\n",
                     "      <td>0.213845</td>\n",
                     "      <td>0.769175</td>\n",
                     "      <td>0.799850</td>\n",
                     "      <td>0.784212</td>\n",
                     "      <td>0.917633</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>37</td>\n",
                     "      <td>0.002500</td>\n",
                     "      <td>0.221844</td>\n",
                     "      <td>0.759166</td>\n",
                     "      <td>0.794582</td>\n",
                     "      <td>0.776471</td>\n",
                     "      <td>0.912749</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>38</td>\n",
                     "      <td>0.002500</td>\n",
                     "      <td>0.225129</td>\n",
                     "      <td>0.747346</td>\n",
                     "      <td>0.794582</td>\n",
                     "      <td>0.770241</td>\n",
                     "      <td>0.910405</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>39</td>\n",
                     "      <td>0.002500</td>\n",
                     "      <td>0.226154</td>\n",
                     "      <td>0.748754</td>\n",
                     "      <td>0.791573</td>\n",
                     "      <td>0.769568</td>\n",
                     "      <td>0.910145</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <td>40</td>\n",
                     "      <td>0.002200</td>\n",
                     "      <td>0.225091</td>\n",
                     "      <td>0.754811</td>\n",
                     "      <td>0.796840</td>\n",
                     "      <td>0.775256</td>\n",
                     "      <td>0.912033</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table><p>"
                  ],
                  "text/plain":[
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata":{
                  
               },
               "output_type":"display_data"
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n",
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "\n",
                  "\n",
                  "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
                  "\n",
                  "\n"
               ]
            },
            {
               "data":{
                  "text/plain":[
                     "TrainOutput(global_step=7640, training_loss=0.007843361919775058, metrics={'train_runtime': 22257.0808, 'train_samples_per_second': 5.472, 'train_steps_per_second': 0.343, 'total_flos': 2.89730746368e+16, 'train_loss': 0.007843361919775058, 'epoch': 40.0})"
                  ]
               },
               "execution_count":30,
               "metadata":{
                  
               },
               "output_type":"execute_result"
            }
         ],
         "source":[
            "trainer.set_things(labelids, tokenizer, beamsz)\n",
            "trainer.train()"
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            
         },
         "source":[
            "### learning_rate=3e-4, batch_size=16,weight_decay=1e-4"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":31,
         "metadata":{
            "scrolled":true
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "PyTorch: setting up devices\n",
                  "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
               ]
            }
         ],
         "source":[
            "args = Seq2SeqTrainingArguments(\n",
            "    \"T5-pretrained-labelseq-ner-logitsprocessor-lr3e-4-batch-16-wd-1e-4\", evaluation_strategy=\"epoch\", save_strategy=\"epoch\",\n",
            "    learning_rate=3e-4, num_train_epochs=40, weight_decay=1e-4, predict_with_generate=True,\n",
            "    per_device_train_batch_size=16, seed=7, #     no_cuda=True,\n",
            "    )\n",
            "\n",
            "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
            "trainer = MyTrainer(\n",
            "    model=model, args=args, train_dataset=training_set, eval_dataset=val_set,\n",
            "    data_collator=data_collator, compute_metrics=compute_metrics, tokenizer=tokenizer,\n",
            ")\n",
            "beamsz = 5"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":null,
         "metadata":{
            
         },
         "outputs":[
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "/home/nanomineduke/anaconda3/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
                  "  FutureWarning,\n",
                  "***** Running training *****\n",
                  "  Num examples = 3045\n",
                  "  Num Epochs = 40\n",
                  "  Instantaneous batch size per device = 16\n",
                  "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
                  "  Gradient Accumulation steps = 1\n",
                  "  Total optimization steps = 7640\n"
               ]
            },
            {
               "data":{
                  "text/html":[
                     "\n",
                     "    <div>\n",
                     "      \n",
                     "      <progress value='224' max='7640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                     "      [ 224/7640 09:55 < 5:31:22, 0.37 it/s, Epoch 1.17/40]\n",
                     "    </div>\n",
                     "    <table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     " <tr style=\"text-align: left;\">\n",
                     "      <th>Epoch</th>\n",
                     "      <th>Training Loss</th>\n",
                     "      <th>Validation Loss</th>\n",
                     "      <th>Precision</th>\n",
                     "      <th>Recall</th>\n",
                     "      <th>F1</th>\n",
                     "      <th>Accuracy</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <td>1</td>\n",
                     "      <td>No log</td>\n",
                     "      <td>0.173764</td>\n",
                     "      <td>0.714286</td>\n",
                     "      <td>0.775019</td>\n",
                     "      <td>0.743414</td>\n",
                     "      <td>0.897643</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table><p>"
                  ],
                  "text/plain":[
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata":{
                  
               },
               "output_type":"display_data"
            },
            {
               "name":"stderr",
               "output_type":"stream",
               "text":[
                  "***** Running Evaluation *****\n",
                  "  Num examples = 762\n",
                  "  Batch size = 8\n"
               ]
            }
         ],
         "source":[
            "trainer.set_things(labelids, tokenizer, beamsz)\n",
            "trainer.train()"
         ]
      },
      {
         "cell_type":"code",
         "execution_count":null,
         "metadata":{
            
         },
         "outputs":[
            
         ],
         "source":[
            
         ]
      }
   ],
   "metadata":{
      "kernelspec":{
         "display_name":"Python 3",
         "language":"python",
         "name":"python3"
      },
      "language_info":{
         "codemirror_mode":{
            "name":"ipython",
            "version":3
         },
         "file_extension":".py",
         "mimetype":"text/x-python",
         "name":"python",
         "nbconvert_exporter":"python",
         "pygments_lexer":"ipython3",
         "version":"3.7.4"
      }
   },
   "nbformat":4,
   "nbformat_minor":4
}
